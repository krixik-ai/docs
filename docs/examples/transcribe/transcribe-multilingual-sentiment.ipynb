{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multilingual-to-english transcription with sentiment analysis pipeline\n",
    "\n",
    "This document details a modular pipeline that takes in an audio/video file in a non-english language, transcribes it, translates the transcription into english, and then performs sentiment analysis on each sentence of the translated transcript.\n",
    "\n",
    "A table of contents for the remainder of this document is shown below.\n",
    "\n",
    "\n",
    "- [pipeline setup](#pipeline-setup)\n",
    "- [processing a file](#processing-a-file)\n",
    "- [performing semantic search](#performing-semantic-search)\n",
    "- [saving the pipeline config for future use](#saving-the-pipeline-config-for-future-use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "# import utilities\n",
    "import sys \n",
    "import json\n",
    "import importlib\n",
    "sys.path.append('../../../')\n",
    "reset = importlib.import_module(\"utilities.reset\")\n",
    "reset_pipeline = reset.reset_pipeline\n",
    "\n",
    "# load secrets from a .env file using python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../../.env\")\n",
    "MY_API_KEY = os.getenv('MY_API_KEY')\n",
    "MY_API_URL = os.getenv('MY_API_URL')\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = MY_API_KEY, \n",
    "            api_url = MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we setup a multi module pipeline to serve our intended purpose, which is to build a pipeline that will transcribe any audio/video in a non-english language, translate the content of the corresponding transcription into english, and then perform sentiment analysis on the result - sentence-by-sentence.\n",
    "\n",
    "To do this we will use the following modules:\n",
    "\n",
    "- [`transcribe`](modules/transcribe.md): takes in audio/video input, outputs json of content transcription\n",
    "- [`translate`](modules/translate.md): takes in json of text snippets, outputs json of translated snippets\n",
    "- [`json-to-txt`](modules/json-to-txt.md): takes in json of text snippets, merges into text file\n",
    "- [`parser`](modules/parser.md): takes in text, slices into (possibly overlapping) strings\n",
    "- [`sentiment`](modules/sentiment): takes in text snippets and returns scores for their sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this by passing the module names to the `module_chain` argument of [`create_pipeline`](system/create_save_load.md) along with a name for our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a multi-module pipeline\n",
    "pipeline = krixik.create_pipeline(name=\"examples-transcribe-multilingual-sentiment-docs\",\n",
    "                                  module_chain=[\"transcribe\",\n",
    "                                                \"translate\",\n",
    "                                                \"json-to-txt\",\n",
    "                                                \"parser\",\n",
    "                                                \"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our `custom` pipeline built we now pass it, along with a test file, to our operator to process the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a quick look at a test file before processing.\n",
    "\n",
    "This is a short video in spanish.  After transcription we will translate it into english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"../../../data/input/deadlift.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine contents of input file\n",
    "test_file = \"../../../data/input/deadlift.mp4\"\n",
    "from IPython.display import Video\n",
    "Video(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input video content language content is English.  We will use the `opus-mt-en-es` model of the [`translate`](modules/translate.md) to translate the transcript of this video into Spanish.\n",
    "\n",
    "For this run we will use the default models for the remainder of the modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted ../../../data/input/deadlift.mp4 to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmphh53msr4/krixik_converted_version_deadlift.mp3\n",
      "INFO: hydrated input modules: {'module_1': {'model': 'whisper-tiny', 'params': {}}, 'module_2': {'model': 'opus-mt-es-en', 'params': {}}, 'module_3': {'model': 'base', 'params': {}}, 'module_4': {'model': 'sentence', 'params': {}}, 'module_5': {'model': 'distilbert-base-uncased-finetuned-sst-2-english', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_file_name_rhlnmnumla.mp3\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 600 seconds, at Mon May  6 15:44:33 2024 UTC\n",
      "INFO: examples-transcribe-multilingual-sentiment-docs file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This process's request_id is: 984754c6-e6df-0d1a-daae-25aa2d6fe7ce\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 5) - transcribe processing complete.\n",
      "SUCCESS: module 2 (of 5) - translate processing complete.\n",
      "SUCCESS: module 3 (of 5) - json-to-txt processing complete.\n",
      "SUCCESS: module 4 (of 5) - parser processing complete.\n",
      "SUCCESS: module 5 (of 5) - sentiment processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# test file\n",
    "test_file = \"../../../data/input/deadlift.mp4\"\n",
    "\n",
    "# process test input\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  expire_time=60*10,\n",
    "                                  modules={\"translate\": {\"model\": \"opus-mt-es-en\"}},\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this process is printed below.  Because the output of this particular pipeline is a database file, the process output is shown as null in the output.  The local address of the output file itself has been returned to the address noted in the `process_output_files` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"examples-transcribe-multilingual-sentiment-docs\",\n",
      "  \"request_id\": \"718000ab-edd3-4554-a38c-89a3cdebf394\",\n",
      "  \"file_id\": \"7c1d7f56-36aa-4beb-824e-772e50140506\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 7c1d7f56-36aa-4beb-824e-772e50140506.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"To begin, we want to see the feet in the anchors of the chair and the men, the columns in the ground, a neutral column, mediated by the abdomen, the men are going to go through there.\",\n",
      "      \"positive\": 0.985,\n",
      "      \"negative\": 0.015,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"The men are lightly in front of the bar or in the top, the men are symmetric and sufficient to not be in the knees.\",\n",
      "      \"positive\": 0.573,\n",
      "      \"negative\": 0.427,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"We can have a look at the front.\",\n",
      "      \"positive\": 0.998,\n",
      "      \"negative\": 0.002,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"To make movement, we have to put the columns in front of the bar and start to move the Shoulders and the Shoulders together.\",\n",
      "      \"positive\": 0.004,\n",
      "      \"negative\": 0.996,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"When the bar goes to the knees, we extend the knee.\",\n",
      "      \"positive\": 0.925,\n",
      "      \"negative\": 0.075,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"To return, we will return the reflection of the knees and the back of the chair, and the chess.\",\n",
      "      \"positive\": 0.996,\n",
      "      \"negative\": 0.004,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"When the bar goes to the knees, we have the correct angle of the trunk, and we double the knees until the head is approximately half of the head, to position the beginning and rest.\",\n",
      "      \"positive\": 0.006,\n",
      "      \"negative\": 0.994,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"To make all the movement, we want to see the bar close to the body, raise and lower.\",\n",
      "      \"positive\": 0.982,\n",
      "      \"negative\": 0.018,\n",
      "      \"neutral\": 0.0\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"/Users/jeremywatt/Desktop/krixik/code/krixik-docs/docs/examples/transcribe/7c1d7f56-36aa-4beb-824e-772e50140506.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "print(json.dumps(process_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our pipeline has `text-embedder` and `vector-db` modules we can semantically search the translated transcription, here in Spanish (since we processed our file with an English-Spanish model).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KrixikBasePipeline' object has no attribute 'semantic_search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# semantically search translated transcription\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m search_output \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msemantic_search\u001b[49m(query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhechos realmente bsicos\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      3\u001b[0m                                          file_ids\u001b[38;5;241m=\u001b[39m[process_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(search_output, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KrixikBasePipeline' object has no attribute 'semantic_search'"
     ]
    }
   ],
   "source": [
    "# semantically search translated transcription\n",
    "search_output = pipeline.semantic_search(query=\"hechos realmente bsicos\", \n",
    "                                         file_ids=[process_output[\"file_id\"]])\n",
    "\n",
    "print(json.dumps(search_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about the [`semantic_search` method here](system/semantic_search.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
