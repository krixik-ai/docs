{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantically searchable multilingual transcription pipeline\n",
    "\n",
    "This document details a modular pipeline that takes in an audio/video file, transcribes it, translates the transcription into a desired language, and makes the result semantically searchable.\n",
    "\n",
    "A table of contents for the remainder of this document is shown below.\n",
    "\n",
    "\n",
    "- [pipeline setup](#pipeline-setup)\n",
    "- [processing a file](#processing-a-file)\n",
    "- [performing semantic search](#performing-semantic-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# import utilities\n",
    "import sys \n",
    "import json\n",
    "import importlib\n",
    "sys.path.append('../../../')\n",
    "reset = importlib.import_module(\"utilities.reset\")\n",
    "reset_pipeline = reset.reset_pipeline\n",
    "\n",
    "# load secrets from a .env file using python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../../.env\")\n",
    "MY_API_KEY = os.getenv('MY_API_KEY')\n",
    "MY_API_URL = os.getenv('MY_API_URL')\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = MY_API_KEY, \n",
    "            api_url = MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we setup a multi module pipeline to serve our intended purpose, which is to build a pipeline that will transcribe any audio/video and make it semantically searchable in any language.\n",
    "\n",
    "To do this we will use the following modules:\n",
    "\n",
    "- [`transcribe`](modules/transcribe.md): takes in audio/video input, outputs json of content transcription\n",
    "- [`translate`](modules/translate.md): takes in json of text snippets, outputs json of translated snippets\n",
    "- [`json-to-txt`](modules/json-to-txt.md): takes in json of text snippets, merges into text file\n",
    "- [`parser`](modules/parser.md): takes in text, slices into (possibly overlapping) strings\n",
    "- [`text-embedder`](modules/text-embedder.md): takes in text snippets, creates vector representation of each outputing an npy file\n",
    "- [`vector-db`](modules/vector-db.md): takes in npy of vectors, outputs vector db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this by passing the module names to the `module_chain` argument of [`create_pipeline`](system/create_save_load.md) along with a name for our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a multi-module pipeline\n",
    "pipeline = krixik.create_pipeline(name=\"examples-transcribe-semantic-multilingual-docs\",\n",
    "                                  module_chain=[\"transcribe\",\n",
    "                                                \"translate\",\n",
    "                                                \"json-to-txt\",\n",
    "                                                \"parser\",\n",
    "                                                \"text-embedder\",\n",
    "                                                \"vector-db\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline's available modeling options and parameters are stored in your custom [pipeline's configuration](system/create_save_load.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define a path to a local input file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a quick look at this file before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"../../input_data/Interesting Facts About Colombia.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine contents of input file\n",
    "test_file = \"../../../data/input/Interesting Facts About Colombia.mp4\"\n",
    "from IPython.display import Video\n",
    "Video(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input video content language content is English.  We will use the `opus-mt-en-es` model of the [`translate`](modules/translate.md) to translate the transcript of this video into Spanish.\n",
    "\n",
    "For this run we will use the default models for the remainder of the modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted ../../input_data/Interesting Facts About Colombia.mp4 to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmps__us5t0/krixik_converted_version_Interesting Facts About Colombia.mp3\n",
      "INFO: hydrated input modules: {'transcribe': {'model': 'whisper-tiny', 'params': {}}, 'translate': {'model': 'opus-mt-en-es', 'params': {}}, 'json-to-txt': {'model': 'base', 'params': {}}, 'parser': {'model': 'sentence', 'params': {}}, 'text-embedder': {'model': 'multi-qa-MiniLM-L6-cos-v1', 'params': {'quantize': True}}, 'vector-db': {'model': 'faiss', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_file_name_oogbwiauhc.mp3\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 300 seconds, at Mon Apr 29 18:06:15 2024 UTC\n",
      "INFO: transcribe-translate-semantic-pipeline file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This process's request_id is: 3a4197ea-3507-c901-245f-a8faffa69009\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 6) - transcribe processing complete.\n",
      "SUCCESS: module 2 (of 6) - translate processing complete.\n",
      "SUCCESS: module 3 (of 6) - json-to-txt processing complete.\n",
      "SUCCESS: module 4 (of 6) - parser processing complete.\n",
      "SUCCESS: module 5 (of 6) - text-embedder processing complete.\n",
      "SUCCESS: module 6 (of 6) - vector-db processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# test file\n",
    "test_file = \"../../../data/input/Interesting Facts About Colombia.mp4\"\n",
    "\n",
    "# process test input\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  expire_time=60*10,\n",
    "                                  modules={\"translate\": {\"model\": \"opus-mt-en-es\"}},\n",
    "                                  verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this process is printed below.  Because the output of this particular pipeline is a database file, the process output is shown as null in the output.  The local address of the output file itself has been returned to the address noted in the `process_output_files` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"transcribe-translate-semantic-pipeline\",\n",
      "  \"request_id\": \"b4e43bd1-bb20-4872-b93e-8f640fb34193\",\n",
      "  \"file_id\": \"2926aa4e-5c01-4e49-9e83-5eb10a926ef1\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 2926aa4e-5c01-4e49-9e83-5eb10a926ef1.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"/Users/jeremywatt/Desktop/krixik-cli/docs/examples/transcribe/2926aa4e-5c01-4e49-9e83-5eb10a926ef1.faiss\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "print(json.dumps(process_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our pipeline has `text-embedder` and `vector-db` modules we can semantically search the translated transcription, here in Spanish (since we processed our file with an English-Spanish model).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"3b4f827c-e685-4157-b445-6c79c1ad7ab3\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"2926aa4e-5c01-4e49-9e83-5eb10a926ef1\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"krixik_generated_file_name_oogbwiauhc.mp3\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 39,\n",
      "        \"created_at\": \"2024-04-30 01:01:18\",\n",
      "        \"last_updated\": \"2024-04-30 01:01:18\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"Miramos algunos hechos realmente bsicos.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.093\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Bienvenidos de nuevo a los hechos F2D.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.267\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Es interesante el hecho de que en 2007, los principales lugares que equivalan a una zona de amortiguacin de aproximadamente 207.000 hectreas, que se denominan el paisaje cultural del caf, fueron considerados Patrimonio de la Humanidad por la UNESCO.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.292\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"S. Entonces me estoy pagando por esto.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.313\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Bueno, lo soy.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.337\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# semantically search translated transcription\n",
    "search_output = pipeline.semantic_search(query=\"hechos realmente bsicos\", \n",
    "                                         file_ids=[process_output[\"file_id\"]])\n",
    "\n",
    "print(json.dumps(search_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about the [`semantic_search` method here](system/semantic_search.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
