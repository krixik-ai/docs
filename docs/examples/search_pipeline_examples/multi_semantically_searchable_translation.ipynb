{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Module Pipeline: Semantically-Searchable Translation\n",
    "\n",
    "This document details a modular pipeline that takes in text, [`translates`](../modules/ai_model_modules/translate_module.md) it into a desired language, and makes the result [`semantically searchable`](../system/search_methods/semantic_search_method.md).\n",
    "\n",
    "The document is divided into the following sections:\n",
    "\n",
    "- [Pipeline Setup](#pipeline-setup)\n",
    "- [Processing an Input File](#processing-an-input-file)\n",
    "- [Performing Semantic Search](#performing-semantic-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Setup\n",
    "\n",
    "To achieve what we've described above, let's set up a pipeline sequentially consisting of the following modules:\n",
    "\n",
    "- A [`parser`](../modules/ai_model_modules/parser_module.md) module.\n",
    "\n",
    "- A [`translate`](../modules/ai_model_modules/translate_module.md) module.\n",
    "\n",
    "- A [`text-embedder`](../modules/ai_model_modules/text-embedder_module.md) module.\n",
    "\n",
    "- A [`vector-db`](../modules/database_modules/vector-db_module.md) module.\n",
    "\n",
    "We do this by leveraging the [`.create_pipeline`](../system/pipeline_creation/create_pipeline.md) method, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline as detailed above\n",
    "\n",
    "pipeline_1 = krixik.create_pipeline(name=\"multi_keyword_searchable_transcription\",\n",
    "                                    module_chain=[\"parser\",\n",
    "                                                  \"translate\",\n",
    "                                                  \"text-embedder\",\n",
    "                                                  \"vector-db\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing an Input File\n",
    "\n",
    "Lets take a quick look at a test file before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRÓLOGO\n",
      "\n",
      "Desocupado lector: sin juramento me podrás creer que quisiera que este\n",
      "libro, como hijo del entendimiento, fuera el más hermoso, el más gallardo y\n",
      "más discreto que pudiera imaginarse. Pero no he podido yo contravenir al\n",
      "orden de naturaleza; que en ella cada cosa engendra su semejante. Y así,\n",
      "¿qué podrá engendrar el estéril y mal cultivado ingenio mío, sino la\n",
      "historia de un hijo seco, avellanado, antojadizo y lleno de pensamientos\n",
      "varios y nunca imaginados de otro alguno, bien como quien se engendró en\n",
      "una cárcel, donde toda incomodidad tiene su asiento y donde todo triste\n",
      "ruido hace su habitación? El sosiego, el lugar apacible, la amenidad de los\n",
      "campos, la serenidad de los cielos, el murmurar de las fuentes, la quietud\n",
      "del espíritu son grande parte para que las musas más estériles se muestren\n",
      "fecundas y ofrezcan partos al mundo que le colmen de maravilla y de\n",
      "contento. Acontece tener un padre un hijo feo y sin gracia alguna, y el\n",
      "amor que le tiene le pone una venda en los ojos para que no vea sus faltas,\n",
      "antes las juzga por discreciones y lindezas y las cuenta a sus amigos por\n",
      "agudezas y donaires. Pero yo, que, aunque parezco padre, soy padrastro de\n",
      "Don Quijote, no quiero irme con la corriente del uso, ni suplicarte, casi\n",
      "con las lágrimas en los ojos, como otros hacen, lector carísimo, que\n",
      "perdones o disimules las faltas que en este mi hijo vieres; y ni eres su\n",
      "pariente ni su amigo, y tienes tu alma en tu cuerpo y tu libre albedrío\n",
      "como el más pintado, y estás en tu casa, donde eres señor della, como el\n",
      "rey de sus alcabalas, y sabes lo que comúnmente se dice: que debajo de mi\n",
      "manto, al rey mato. Todo lo cual te esenta y hace libre de todo respecto y\n",
      "obligación; y así, puedes decir de la historia todo aquello que te\n",
      "pareciere, sin temor que te calunien por el mal ni te premien por el bien\n",
      "que dijeres della.\n"
     ]
    }
   ],
   "source": [
    "# examine contents of input file\n",
    "\n",
    "with open(\"../../../data/input/don_esp.txt\", \"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the input text is in Spanish, we'll use the (non-default) [`opus-mt-es-en`](https://huggingface.co/Helsinki-NLP/opus-mt-es-en) model of the [`translate`](../modules/ai_model_modules/translate_module.md) module to translate it into English.\n",
    "\n",
    "We will use the default models for every other module in the pipeline, so they don't have to be specified in the [`modules`](../system/parameters_processing_files_through_pipelines/process_method.md#selecting-models-via-the-modules-argument) argument of the [`.process`](../system/parameters_processing_files_through_pipelines/process_method.md) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: hydrated input modules: {'module_1': {'model': 'sentence', 'params': {}}, 'module_2': {'model': 'opus-mt-es-en', 'params': {}}, 'module_3': {'model': 'base', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_file_name_bkryhqmkdo.txt\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 600 seconds, at Tue May  7 12:45:30 2024 UTC\n",
      "INFO: examples-translate-text-search-pipeline file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This process's request_id is: 890866e1-3a68-1927-5439-628eac7dca13\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 3) - parser processing complete.\n",
      "SUCCESS: module 2 (of 3) - translate processing complete.\n",
      "SUCCESS: module 3 (of 3) - json-to-txt processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# process the file through the pipeline, as described above\n",
    "\n",
    "process_output_1 = pipeline_1.process(local_file_path = \"../../../data/input/don_esp.txt\", # the initial local filepath where the input file is stored\n",
    "                                      local_save_directory=\"../../../data/output\", # the local directory that the output file will be saved to\n",
    "                                      expire_time=60*30, # process data will be deleted from the Krixik system in 30 minutes\n",
    "                                      wait_for_process=True, # wait for process to complete before returning IDE control to user\n",
    "                                      verbose=False, # do not display process update printouts upon running code\n",
    "                                      modules={\"translate\": {\"model\": \"opus-mt-es-en\"}}) # specify a non-default model for use in the translate module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this process is printed below. To learn more about each component of the output, review documentation for the [`.process`](../system/parameters_processing_files_through_pipelines/process_method.md) method.\n",
    "\n",
    "Because the output of this particular module-model pair is a [FAISS](https://github.com/facebookresearch/faiss) database file, `process_output` is \"null\". However, the output file has been saved to the location noted in the `process_output_files` key.  The `file_id` of the processed input is used as a filename prefix for the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"examples-translate-text-search-pipeline\",\n",
      "  \"request_id\": \"d8363ef8-4fe9-4ba1-904a-76a603a8d4d3\",\n",
      "  \"file_id\": \"8b907667-1472-4130-83f5-9b4a82bdb5ee\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 8b907667-1472-4130-83f5-9b4a82bdb5ee.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"../../../data/output/8b907667-1472-4130-83f5-9b4a82bdb5ee.txt\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "\n",
    "print(json.dumps(process_output_1, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Semantic Search\n",
    "\n",
    "Krixik's [`.semantic_search`](../system/search_methods/semantic_search_method.md) method enables semantic search on documents processed through certain pipelines. Given that the [`.semantic_search`](../system/search_methods/semantic_search_method.md) method both [embeds](../modules/ai_model_modules/text-embedder_module.md) the query and performs the search, it can only be used with pipelines containing both a [`text-embedder`](../modules/ai_model_modules/text-embedder_module.md) module and a [`vector-db`](../modules/database_modules/vector-db_module.md) module in immediate succession.\n",
    "\n",
    "Since our pipeline satisfies this condition, it has access to the [`.semantic_search`](../system/search_methods/semantic_search_method.md) method. Let's use it to query our text with natural language, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"d88bf437-a742-41c1-8b28-5981d5c44bcc\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"e0024f60-9192-4e05-8bb3-a0a0423305ab\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"krixik_generated_file_name_tnzlfqdsly.mp3\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 41,\n",
      "        \"created_at\": \"2024-04-29 22:57:52\",\n",
      "        \"last_updated\": \"2024-04-29 22:57:52\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"Learn about Columbia.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.263\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"And I know coffee is really important when it comes to talking about Columbia, but you guys really don't know how important it is with its culture.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.287\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"You Columbia coffee right here.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.292\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Now interesting enough when it comes to the coffee in Columbia, believe it or not, it is not actually native to the country.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.298\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"So we all know Columbia is famous for its coffee, right?\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.306\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# perform semantic_search over the file in the pipeline\n",
    "\n",
    "semantic_output_1 = pipeline_1.semantic_search(query=\"Sterile ideas bring little to man\", \n",
    "                                               file_ids=[\"XXXXX\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "\n",
    "print(json.dumps(semantic_output_1, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "\n",
    "reset_pipeline(pipeline_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
