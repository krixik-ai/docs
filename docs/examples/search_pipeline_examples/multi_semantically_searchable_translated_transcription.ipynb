{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Module Pipeline: Semantically-Searchable Translated Transcription\n",
    "\n",
    "This document details a modular pipeline that takes in an audio/video file, [`transcribes`](../modules/ai_model_modules/transcribe_module.md) it, [`translates`](../modules/ai_model_modules/translate_module.md) the transcription into a desired language, and makes the result [`semantically searchable`](../system/search_methods/semantic_search_method.md).\n",
    "\n",
    "The document is divided into the following sections:\n",
    "\n",
    "- [Pipeline Setup](#pipeline-setup)\n",
    "- [Processing an Input File](#processing-an-input-file)\n",
    "- [Performing Semantic Search](#performing-semantic-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Setup\n",
    "\n",
    "To achieve what we've described above, let's set up a pipeline sequentially consisting of the following modules:\n",
    "\n",
    "- A [`transcribe`](../modules/ai_model_modules/transcribe_module.md) module.\n",
    "\n",
    "- A [`translate`](../modules/ai_model_modules/translate_module.md) module.\n",
    "\n",
    "- A [`json-to-txt`](../modules/support_function_modules/json-to-txt_module.md) module.\n",
    "\n",
    "- A [`parser`](../modules/ai_model_modules/parser_module.md) module.\n",
    "\n",
    "- A [`text-embedder`](../modules/ai_model_modules/text-embedder_module.md) module.\n",
    "\n",
    "- A [`vector-db`](../modules/database_modules/vector-db_module.md) module.\n",
    "\n",
    "We use the [`json-to-txt`](../modules/support_function_modules/json-to-txt_module.md) and [`parser`](../modules/ai_model_modules/parser_module.md) combination, which combines the transcribed snippets into one document and then splices it again, to make sure that any pauses in speech don't make for partial snippets that can confuse the [`text-embedder`](../modules/ai_model_modules/text-embedder_module.md) model.\n",
    "\n",
    "Pipeline setup is accomplished through the [`.create_pipeline`](../system/pipeline_creation/create_pipeline.md) method, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline as detailed above\n",
    "\n",
    "pipeline_1 = krixik.create_pipeline(name=\"multi_semantically_searchable_translated_transcription\",\n",
    "                                    module_chain=[\"transcribe\",\n",
    "                                                  \"translate\",\n",
    "                                                  \"json-to-txt\",\n",
    "                                                  \"parser\",\n",
    "                                                  \"text-embedder\",\n",
    "                                                  \"vector-db\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing an Input File\n",
    "\n",
    "Lets take a quick look at a test file before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"../../../data/input/Interesting Facts About Colombia.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine contents of input file\n",
    "\n",
    "from IPython.display import Video\n",
    "Video(\"../../../data/input/deadlift.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the input text is in Spanish, we'll use the (non-default) [`opus-mt-es-en`](https://huggingface.co/Helsinki-NLP/opus-mt-es-en) model of the [`translate`](../modules/ai_model_modules/translate_module.md) module to translate it into English.\n",
    "\n",
    "We will use the default models for every other module in the pipeline, so they don't have to be specified in the [`modules`](../system/parameters_processing_files_through_pipelines/process_method.md#selecting-models-via-the-modules-argument) argument of the [`.process`](../system/parameters_processing_files_through_pipelines/process_method.md) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted ../../../data/input/Interesting Facts About Colombia.mp4 to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmpvnfz4nvg/krixik_converted_version_Interesting Facts About Colombia.mp3\n",
      "INFO: hydrated input modules: {'module_1': {'model': 'whisper-tiny', 'params': {}}, 'module_2': {'model': 'opus-mt-en-es', 'params': {}}, 'module_3': {'model': 'base', 'params': {}}, 'module_4': {'model': 'sentence', 'params': {}}, 'module_5': {'model': 'all-MiniLM-L6-v2', 'params': {'quantize': True}}, 'module_6': {'model': 'faiss', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_file_name_qfgbnrugsa.mp3\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 600 seconds, at Mon May  6 12:23:47 2024 UTC\n",
      "INFO: examples-transcribe-semantic-multilingual-docs file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This process's request_id is: 8842c45c-bce2-3d52-8426-f26c872ed546\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 6) - transcribe processing complete.\n",
      "SUCCESS: module 2 (of 6) - translate processing complete.\n",
      "SUCCESS: module 3 (of 6) - json-to-txt processing complete.\n",
      "SUCCESS: module 4 (of 6) - parser processing complete.\n",
      "SUCCESS: module 5 (of 6) - text-embedder processing complete.\n",
      "SUCCESS: module 6 (of 6) - vector-db processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# process the file through the pipeline, as described above\n",
    "\n",
    "process_output_1 = pipeline_1.process(local_file_path = \"../../../data/input/deadlift.mp4\", # the initial local filepath where the input file is stored\n",
    "                                      local_save_directory=\"../../../data/output\", # the local directory that the output file will be saved to\n",
    "                                      expire_time=60*30, # process data will be deleted from the Krixik system in 30 minutes\n",
    "                                      wait_for_process=True, # wait for process to complete before returning IDE control to user\n",
    "                                      verbose=False, # do not display process update printouts upon running code\n",
    "                                      modules={\"translate\": {\"model\": \"opus-mt-es-en\"}}) # specify a non-default model for use in the translate module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this process is printed below. To learn more about each component of the output, review documentation for the [`.process`](../system/parameters_processing_files_through_pipelines/process_method.md) method.\n",
    "\n",
    "Because the output of this particular module-model pair is a [FAISS](https://github.com/facebookresearch/faiss) database file, `process_output` is \"null\". However, the output file has been saved to the location noted in the `process_output_files` key.  The `file_id` of the processed input is used as a filename prefix for the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"examples-transcribe-semantic-multilingual-docs\",\n",
      "  \"request_id\": \"f8ed48c3-b318-48f0-961f-0b9e4cc34b1c\",\n",
      "  \"file_id\": \"600b873e-1bef-471a-a5e9-ae675c0514bc\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 600b873e-1bef-471a-a5e9-ae675c0514bc.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"/Users/jeremywatt/Desktop/krixik/code/krixik-docs/docs/examples/transcribe/600b873e-1bef-471a-a5e9-ae675c0514bc.faiss\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "\n",
    "print(json.dumps(process_output_1, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Semantic Search\n",
    "\n",
    "Krixik's [`.semantic_search`](../system/search_methods/semantic_search_method.md) method enables semantic search on documents processed through certain pipelines. Given that the [`.semantic_search`](../system/search_methods/semantic_search_method.md) method both [embeds](../modules/ai_model_modules/text-embedder_module.md) the query and performs the search, it can only be used with pipelines containing both a [`text-embedder`](../modules/ai_model_modules/text-embedder_module.md) module and a [`vector-db`](../modules/database_modules/vector-db_module.md) module in immediate succession.\n",
    "\n",
    "Since our pipeline satisfies this condition, it has access to the [`.semantic_search`](../system/search_methods/semantic_search_method.md) method. Let's use it to query our text with natural language, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"b9452617-37da-47c6-aac4-70c82074e94d\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"600b873e-1bef-471a-a5e9-ae675c0514bc\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"krixik_generated_file_name_qfgbnrugsa.mp3\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 39,\n",
      "        \"created_at\": \"2024-05-06 19:13:50\",\n",
      "        \"last_updated\": \"2024-05-06 19:13:50\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"Miramos algunos hechos realmente bsicos.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.058\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Bienvenidos de nuevo a los hechos F2D.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.2\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Pero comencemos.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.23\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"S. Entonces me estoy pagando por esto.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.242\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Lo que me recuerda chicos, esto es parte de nuestra lista de Columbia.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.244\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# perform semantic_search over the file in the pipeline\n",
    "\n",
    "semantic_output_1 = pipeline_1.semantic_search(query=\"really basic facts\", \n",
    "                                               file_ids=[process_output_1[\"file_id\"]])\n",
    "\n",
    "# nicely print the output of this process\n",
    "\n",
    "print(json.dumps(semantic_output_1, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "\n",
    "reset_pipeline(pipeline_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
