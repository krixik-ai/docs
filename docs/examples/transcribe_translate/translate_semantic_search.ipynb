{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantically searchable translation\n",
    "\n",
    "This document reviews a semantic search pipeline that can be used to make an input text in a specific language semantically-searchable in another language.\n",
    "\n",
    "\n",
    "- [pipeline setup](#pipeline-setup)\n",
    "- [processing an input file](#processing-an-input-file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "# import utilities\n",
    "import sys \n",
    "import json\n",
    "sys.path.append('../../../')\n",
    "import importlib\n",
    "reset = importlib.import_module(\"utilities.reset\")\n",
    "reset_pipeline = reset.reset_pipeline\n",
    "\n",
    "# load secrets from a .env file using python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../../.env\")\n",
    "MY_API_KEY = os.getenv('MY_API_KEY')\n",
    "MY_API_URL = os.getenv('MY_API_URL')\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = MY_API_KEY, \n",
    "            api_url = MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline setup\n",
    "\n",
    "Below we setup a two pipelines.\n",
    "\n",
    "The first is a single module pipeline consisting of [`translate`](../../modules/translate.md).\n",
    "\n",
    "The latter consists of a [`translate`](../../modules/translate.md), [`parser`](../../modules/parser.md), [`text-embedder`](../../modules/text-embedder.md), and [`vector-db`](../../modules/vector-db.md) modules.  This will allow us to translate input files and make them semantically searchable.\n",
    "\n",
    "We do this by passing the module names to the `module_chain` argument of [`create_pipeline`](../../system/create_save_load.md) along with a name for our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a multi module pipeline to translate an input text file\n",
    "translate_pipeline = krixik.create_pipeline(name=\"examples-translate-text-search-pipeline\",\n",
    "                                            module_chain=[\"parser\", \n",
    "                                                          \"translate\", \n",
    "                                                          \"json-to-txt\"])\n",
    "\n",
    "# create a pipeline with a multi module\n",
    "pipeline = krixik.create_pipeline(name=\"examples-translate-text-search-semantic-pipeline\",\n",
    "                                  module_chain=[\"parser\", \n",
    "                                                \"translate\", \n",
    "                                                \"json-to-txt\", \n",
    "                                                \"parser\",\n",
    "                                                \"text-embedder\", \n",
    "                                                \"vector-db\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline's available modeling options and parameters are stored in your custom [pipeline's configuration](../../system/create_save_load.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(translate_pipeline)\n",
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing an input file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a quick look at a short test file before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRÓLOGO\n",
      "\n",
      "Desocupado lector: sin juramento me podrás creer que quisiera que este\n",
      "libro, como hijo del entendimiento, fuera el más hermoso, el más gallardo y\n",
      "más discreto que pudiera imaginarse. Pero no he podido yo contravenir al\n",
      "orden de naturaleza; que en ella cada cosa engendra su semejante. Y así,\n",
      "¿qué podrá engendrar el estéril y mal cultivado ingenio mío, sino la\n",
      "historia de un hijo seco, avellanado, antojadizo y lleno de pensamientos\n",
      "varios y nunca imaginados de otro alguno, bien como quien se engendró en\n",
      "una cárcel, donde toda incomodidad tiene su asiento y donde todo triste\n",
      "ruido hace su habitación? El sosiego, el lugar apacible, la amenidad de los\n",
      "campos, la serenidad de los cielos, el murmurar de las fuentes, la quietud\n",
      "del espíritu son grande parte para que las musas más estériles se muestren\n",
      "fecundas y ofrezcan partos al mundo que le colmen de maravilla y de\n",
      "contento. Acontece tener un padre un hijo feo y sin gracia alguna, y el\n",
      "amor que le tiene le pone una venda en los ojos para que no vea sus faltas,\n",
      "antes las juzga por discreciones y lindezas y las cuenta a sus amigos por\n",
      "agudezas y donaires. Pero yo, que, aunque parezco padre, soy padrastro de\n",
      "Don Quijote, no quiero irme con la corriente del uso, ni suplicarte, casi\n",
      "con las lágrimas en los ojos, como otros hacen, lector carísimo, que\n",
      "perdones o disimules las faltas que en este mi hijo vieres; y ni eres su\n",
      "pariente ni su amigo, y tienes tu alma en tu cuerpo y tu libre albedrío\n",
      "como el más pintado, y estás en tu casa, donde eres señor della, como el\n",
      "rey de sus alcabalas, y sabes lo que comúnmente se dice: que debajo de mi\n",
      "manto, al rey mato. Todo lo cual te esenta y hace libre de todo respecto y\n",
      "obligación; y así, puedes decir de la historia todo aquello que te\n",
      "pareciere, sin temor que te calunien por el mal ni te premien por el bien\n",
      "que dijeres della.\n"
     ]
    }
   ],
   "source": [
    "# examine contents of input file\n",
    "test_file = \"../../../data/input/don_esp.txt\"\n",
    "with open(test_file, \"r\") as file:\n",
    "    print(file.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we [process](../../system/process.md) the input through our pipeline using the default model for each of our three modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: hydrated input modules: {'module_1': {'model': 'sentence', 'params': {}}, 'module_2': {'model': 'opus-mt-es-en', 'params': {}}, 'module_3': {'model': 'base', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_file_name_bkryhqmkdo.txt\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 600 seconds, at Tue May  7 12:45:30 2024 UTC\n",
      "INFO: examples-translate-text-search-pipeline file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This process's request_id is: 890866e1-3a68-1927-5439-628eac7dca13\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 3) - parser processing complete.\n",
      "SUCCESS: module 2 (of 3) - translate processing complete.\n",
      "SUCCESS: module 3 (of 3) - json-to-txt processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../../data/input/don_esp.txt\"\n",
    "\n",
    "# process a file through the pipeline\n",
    "process_output = translate_pipeline.process(local_file_path = test_file,\n",
    "                                            local_save_directory=\"../../../data/output\",  # save output in current directory\n",
    "                                            expire_time=60*10,         # set all process data to expire in 5 minutes\n",
    "                                            wait_for_process=True,     # wait for process to complete before regaining ide\n",
    "                                            verbose=True,              # set verbosity to False\n",
    "                                            modules={\"translate\": {\"model\": \"opus-mt-es-en\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this process is printed below.  Because the output of this particular pipeline pair is text, the process output is provided in this object is null.  However the file itself has been returned to the address noted in the `process_output_files` key.  The `file_id` of the processed input is used as a filename prefix for the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"examples-translate-text-search-pipeline\",\n",
      "  \"request_id\": \"d8363ef8-4fe9-4ba1-904a-76a603a8d4d3\",\n",
      "  \"file_id\": \"8b907667-1472-4130-83f5-9b4a82bdb5ee\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 8b907667-1472-4130-83f5-9b4a82bdb5ee.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"../../../data/output/8b907667-1472-4130-83f5-9b4a82bdb5ee.txt\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "print(json.dumps(process_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load in the text file output from `process_output_files` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRLOGO Unoccupied reader: without oath you can believe me that I would want this book, as a son of understanding, to be the most beautiful, the most gallant and discreet that could be imagined.\n",
      "But I have not been able to contradict the order of nature; for in it every thing begets its fellowman.\n",
      "And so, what can breed the strill and ill-cultivated wit mo, but the story of a dry son, haphazard, craving and full of various thoughts and never imagined of any other, well as who begets in a crcel, where all discomfort has its seat and where all sad noise makes its habitation?\n",
      "The quietness, the peaceful place, the abundance of the fields, the serenity of the heavens, the murmuring of the fountains, the stillness of the spirit are a great part for the most strile muses to show themselves fruitful and to give birth to the world that fills it with wonder and contentment.\n",
      "It happens to have a father an ugly son with no grace at all, and the love he has puts a blindfold in his eyes so that he does not see his faults, but judges them by discretions and lindezas and tells his friends for acuity and donaires.\n",
      "But I, who, though I look like a father, am Don Quixote's stepfather, do not want to go away with the current of use, nor beg you, almost with the tears in your eyes, as others do, hearty reader, to forgive or to dispel the faults that you see in this my son; and you are neither his relative nor his friend, and you have your soul in your body and your free albedro as the most painted, and you are in your house, where you are seor della, as the king of his palaces, and you know what is commonly said: that under my robe, I kill the king.\n",
      "All that sitteth upon thee, and maketh thee free from all things, and from all things, and from all things that seem unto thee, thou canst say of history, without fear that they may call thee to evil, nor reward thee for the good which thou sayest of it.\n"
     ]
    }
   ],
   "source": [
    "# load in process output from file\n",
    "import json\n",
    "with open(process_output[\"process_output_files\"][0], \"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now process the file with our second pipeline - which will make the outupt searchable in english.\n",
    "\n",
    "We will specify the models we want for the `translate` and second `parser` module using the `modules` argument of the [`process` method](system/process.md).  This will look like\n",
    "\n",
    "```python\n",
    "        modules={\n",
    "            \"module_2\": {\"model\": \"opus-mt-es-en\"},\n",
    "            \"module_4\": {\"model\": \"fixed\", \n",
    "                        \"params\": {\"chunk_size\": 12,\n",
    "                                    \"overlap_size\": 6}}\n",
    "                }\n",
    "```\n",
    "\n",
    "When using mutliple instances of the same module - as we do here (the `parser` module is used twice) - we must instantiate the models based on the module order.  So here `module_2` references our `translate` module, and `module_4` the second `parser` in our `module_chain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: hydrated input modules: {'module_1': {'model': 'sentence', 'params': {}}, 'module_2': {'model': 'opus-mt-es-en', 'params': {}}, 'module_3': {'model': 'base', 'params': {}}, 'module_4': {'model': 'fixed', 'params': {'chunk_size': 12, 'overlap_size': 6}}, 'module_5': {'model': 'all-MiniLM-L6-v2', 'params': {'quantize': True}}, 'module_6': {'model': 'faiss', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_file_name_omgbefdcqw.txt\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 600 seconds, at Tue May  7 12:53:00 2024 UTC\n",
      "INFO: examples-translate-text-search-semantic-pipeline file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This process's request_id is: 2a37b4d8-629f-e350-77f3-4ed37b04a7c0\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 2 (of 5) - translate processing complete.\n",
      "SUCCESS: module 1 (of 5) - parser processing complete.\n",
      "SUCCESS: module 3 (of 5) - json-to-txt processing complete.\n",
      "SUCCESS: module 4 (of 5) - text-embedder processing complete.\n",
      "SUCCESS: module 5 (of 5) - vector-db processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../../data/input/don_esp.txt\"\n",
    "\n",
    "# process a file through the pipeline\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\"../../../data/output\",  # save output in current directory\n",
    "                                  expire_time=60*10,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,     # wait for process to complete before regaining ide\n",
    "                                  verbose=True,              # set verbosity to False\n",
    "                                  modules={\n",
    "                                      \"module_2\": {\"model\": \"opus-mt-es-en\"},\n",
    "                                      \"module_4\": {\"model\": \"fixed\", \n",
    "                                                   \"params\": {\"chunk_size\": 12,\n",
    "                                                              \"overlap_size\": 6}}\n",
    "                                           })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `semantic_search` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "krixik's [`semantic_search` method](../../system/semantic_search.md) is a convenience function for both embedding and querying - and so can only be used with pipelines containing both `text-embedder` and `vector-db` modules in succession.  Since our pipeline here satisfies this condition, it has access to the `semantic_search` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can query our text with natural language as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"4edd8fd4-4c5e-486b-8e95-9b9a1462bcf0\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"accccba9-5326-4fae-89f9-84e55fd2af4e\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"krixik_generated_file_name_omgbefdcqw.txt\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 60,\n",
      "        \"created_at\": \"2024-05-07 19:43:03\",\n",
      "        \"last_updated\": \"2024-05-07 19:43:03\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"a father an ugly son with no grace at all, and the\",\n",
      "          \"line_numbers\": [\n",
      "            5\n",
      "          ],\n",
      "          \"distance\": 0.195\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"that you see in this my son; and you are neither his\",\n",
      "          \"line_numbers\": [\n",
      "            6\n",
      "          ],\n",
      "          \"distance\": 0.224\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"son; and you are neither his relative nor his friend, and you\",\n",
      "          \"line_numbers\": [\n",
      "            6\n",
      "          ],\n",
      "          \"distance\": 0.247\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"and contentment. It happens to have a father an ugly son with\",\n",
      "          \"line_numbers\": [\n",
      "            4,\n",
      "            5\n",
      "          ],\n",
      "          \"distance\": 0.257\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"I look like a father, am Don Quixote's stepfather, do not want\",\n",
      "          \"line_numbers\": [\n",
      "            6\n",
      "          ],\n",
      "          \"distance\": 0.281\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# perform semantic_search over the input file\n",
    "semantic_output = pipeline.semantic_search(\n",
    "    query=\"an unattractive son\", file_ids=[process_output[\"file_id\"]]\n",
    ")\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(semantic_output, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(translate_pipeline)\n",
    "reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
