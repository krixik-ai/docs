{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Module Pipeline: Sentiment Analysis on Translation\n",
    "\n",
    "This document details a modular pipeline that takes in an a text file in a non-English language, [`translates`](../../modules/ai_model_modules/translate_module.md) it into English, and then performs [`sentiment analysis`](../../modules/ai_model_modules/sentiment_module.md) on each sentence of the translation.\n",
    "\n",
    "The document is divided into the following sections:\n",
    "\n",
    "- [Pipeline Setup](#pipeline-setup)\n",
    "- [Processing an Input File](#processing-an-input-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "# import utilities\n",
    "import sys \n",
    "import json\n",
    "import importlib\n",
    "sys.path.append('../../../')\n",
    "reset = importlib.import_module(\"utilities.reset\")\n",
    "reset_pipeline = reset.reset_pipeline\n",
    "\n",
    "# load secrets from a .env file using python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../../../.env\")\n",
    "MY_API_KEY = os.getenv('MY_API_KEY')\n",
    "MY_API_URL = os.getenv('MY_API_URL')\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = MY_API_KEY, \n",
    "            api_url = MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Setup\n",
    "\n",
    "To achieve what we've described above, let's set up a pipeline sequentially consisting of the following modules:\n",
    "\n",
    "- A [`parser`](../../modules/support_function_modules/parser_module.md) module.\n",
    "\n",
    "- A [`translate`](../../modules/ai_model_modules/translate_module.md) module.\n",
    "\n",
    "- A [`sentiment`](../../modules/ai_model_modules/sentiment_module.md) module.\n",
    "\n",
    "We do this by leveraging the [`.create_pipeline`](../../system/pipeline_creation/create_pipeline.md) method, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline as detailed above\n",
    "pipeline = krixik.create_pipeline(name=\"multi_sentiment_analysis_on_translation\",\n",
    "                                  module_chain=[\"parser\",\n",
    "                                                \"translate\",\n",
    "                                                \"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing an Input File\n",
    "\n",
    "Given that we're [`translating`](../../modules/ai_model_modules/translate_module.md) and then performing [`sentiment analysis`](../../modules/ai_model_modules/sentiment_module.md), we'll start with a file in Spanish. Since the input text is in Spanish, we'll use the (non-default) [`opus-mt-es-en`](https://huggingface.co/Helsinki-NLP/opus-mt-es-en) model of the [`translate`](../../modules/ai_model_modules/translate_module.md) module to translate it into English.\n",
    "\n",
    "We will use the default models for every other module in the pipeline, so they don't have to be specified in the [`modules`](../../system/parameters_processing_files_through_pipelines/process_method.md#selecting-models-via-the-modules-argument) argument of the [`.process`](../../system/parameters_processing_files_through_pipelines/process_method.md) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the file through the pipeline, as described above\n",
    "process_output = pipeline.process(local_file_path = \"../../../data/input/spanish_review.txt\", # the initial local filepath where the input file is stored\n",
    "                                  local_save_directory=\"../../../data/output\", # the local directory that the output file will be saved to\n",
    "                                  expire_time=60*30, # process data will be deleted from the Krixik system in 30 minutes\n",
    "                                  wait_for_process=True, # wait for process to complete before returning IDE control to user\n",
    "                                  verbose=False, # do not display process update printouts upon running code\n",
    "                                  modules={\"module_2\": {\"model\": \"opus-mt-es-en\"}}) # specify a non-default model for use in the second module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this process is printed below. To learn more about each component of the output, review documentation for the [`.process`](../../system/parameters_processing_files_through_pipelines/process_method.md) method.\n",
    "\n",
    "Because the output of this particular module-model pair is a JSON file, the process output is provided in this object as well (this is only the case for JSON outputs).  Moreover, the output file itself has been saved to the location noted in the `process_output_files` key.  The `file_id` of the processed input is used as a filename prefix for the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"multi_sentiment_analysis_on_translation\",\n",
      "  \"request_id\": \"e7a6ec00-4d6d-4d14-a23e-60f13e3617f4\",\n",
      "  \"file_id\": \"7d415313-4f8c-4000-855b-4332284a0bbd\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 7d415313-4f8c-4000-855b-4332284a0bbd.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"This silln is fantastic.\",\n",
      "      \"positive\": 1.0,\n",
      "      \"negative\": 0.0,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Besides being supremely comfortable, he feels very firm.\",\n",
      "      \"positive\": 1.0,\n",
      "      \"negative\": 0.0,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"It is made of good strong and durable materials, and cushions are tremendous as well.\",\n",
      "      \"positive\": 1.0,\n",
      "      \"negative\": 0.0,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"What a plush!\",\n",
      "      \"positive\": 0.987,\n",
      "      \"negative\": 0.013,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Very recommended.\",\n",
      "      \"positive\": 1.0,\n",
      "      \"negative\": 0.0,\n",
      "      \"neutral\": 0.0\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"../../../data/output/7d415313-4f8c-4000-855b-4332284a0bbd.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "print(json.dumps(process_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that everything went as it should have, let's load in the text file output from `process_output_files`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"snippet\": \"This silln is fantastic.\",\n",
      "    \"positive\": 1.0,\n",
      "    \"negative\": 0.0,\n",
      "    \"neutral\": 0.0\n",
      "  },\n",
      "  {\n",
      "    \"snippet\": \"Besides being supremely comfortable, he feels very firm.\",\n",
      "    \"positive\": 1.0,\n",
      "    \"negative\": 0.0,\n",
      "    \"neutral\": 0.0\n",
      "  },\n",
      "  {\n",
      "    \"snippet\": \"It is made of good strong and durable materials, and cushions are tremendous as well.\",\n",
      "    \"positive\": 1.0,\n",
      "    \"negative\": 0.0,\n",
      "    \"neutral\": 0.0\n",
      "  },\n",
      "  {\n",
      "    \"snippet\": \"What a plush!\",\n",
      "    \"positive\": 0.987,\n",
      "    \"negative\": 0.013,\n",
      "    \"neutral\": 0.0\n",
      "  },\n",
      "  {\n",
      "    \"snippet\": \"Very recommended.\",\n",
      "    \"positive\": 1.0,\n",
      "    \"negative\": 0.0,\n",
      "    \"neutral\": 0.0\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# load in process output from file\n",
    "with open(process_output[\"process_output_files\"][0]) as f:\n",
    "  print(json.dumps(json.load(f), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may note that, in the first returned snippet, the word \"sill√≥n\" is missing its second vowel and is printed as \"silln\". This is a model issue: the [`translate`](../../modules/ai_model_modules/translate_module.md#available-models-in-the-translate-module) model with which we processed the file may have trouble with accented characters and/or outright remove them. It's important that you familiarize yourself with the peculiarities of AI models you intend to leverage often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
