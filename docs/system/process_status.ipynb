{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `process_status` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `process_status` method is available on every krixik pipeline, and is invoked whenever you want to check the status of files being processed through your defined pipeline.\n",
    "\n",
    "This method is especially useful when using [`process`](system/process.md) with `wait_for_process` set to `False`.\n",
    "\n",
    "- [basic pipeline setup](#basic-pipeline-setup)\n",
    "- [basic usage, required input, and output breakdown](#basic-usage-required-input-and-output-breakdown)\n",
    "- [optional input arguments](#optional-input-arguments)\n",
    "- [defaults when using `process`](#defaults-when-using-process)\n",
    "- [automatic data type transformations](#automatic-data-type-transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "# import utilities\n",
    "import sys \n",
    "import json\n",
    "import importlib\n",
    "sys.path.append('../../')\n",
    "reset = importlib.import_module(\"utilities.reset\")\n",
    "reset_pipeline = reset.reset_pipeline\n",
    "\n",
    "# load secrets from a .env file using python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../../.env\")\n",
    "MY_API_KEY = os.getenv('MY_API_KEY')\n",
    "MY_API_URL = os.getenv('MY_API_URL')\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = MY_API_KEY, \n",
    "            api_url = MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic pipeline setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this document we will use a pipeline consisting of a single [`parser` module](modules/parser.md).  We use [`create_pipeline`](system/create_save_load.md) to instantiate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline with a single module\n",
    "pipeline = krixik.create_pipeline(name=\"system-process-status-docs\",\n",
    "                                  module_chain=[\"parser\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage, required input, and output breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the usage of `process_status` we process a short file illustrated in the introduction to the [`parser` method](modules/parser.md#basic-usage-and-output-breakdown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../data/input/1984_very_short.txt\"\n",
    "\n",
    "# process short input file\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\"../../data/output\", # save output repo data output subdir\n",
    "                                  expire_time=60 * 10,       # set all process data to expire in 10 minutes\n",
    "                                  wait_for_process=False,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False)             # set verbosity to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us examine the returned output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"file_id\": \"3d435c55-05ae-41b6-aee3-76da8c7b0841\",\\n  \"request_id\": \"5e723bee-4939-21f1-52ef-ca0596dd3f1f\",\\n  \"file_name\": \"krixik_generated_file_name_vplttsahnp.txt\",\\n  \"symbolic_directory_path\": \"/etc\",\\n  \"file_tags\": null,\\n  \"file_description\": null\\n}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "print(json.dumps(process_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the status of our process using returned `request_id` and the `process_status` as shown below.  `process_status` takes in a single required input: `request_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"d248636b-5ea5-4da7-a250-9e00332cd2b8\",\n",
      "  \"file_id\": \"3d435c55-05ae-41b6-aee3-76da8c7b0841\",\n",
      "  \"message\": \"SUCCESS: process_status found\",\n",
      "  \"pipeline\": \"process-status-doc\",\n",
      "  \"process_status\": {\n",
      "    \"parser\": false\n",
      "  },\n",
      "  \"overall_status\": \"ongoing\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# use .process_status\n",
    "status_output = pipeline.process_status(request_id=process_output[\"request_id\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(status_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the status of our single module has not yet completed.\n",
    "\n",
    "If we wait a few moments and try again, we will see confirmation that the process completed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"cf1c55e3-34c8-4c81-a940-b264c7c0448d\",\n",
      "  \"file_id\": \"3d435c55-05ae-41b6-aee3-76da8c7b0841\",\n",
      "  \"message\": \"SUCCESS: process_status found\",\n",
      "  \"pipeline\": \"process-status-doc\",\n",
      "  \"process_status\": {\n",
      "    \"parser\": true\n",
      "  },\n",
      "  \"overall_status\": \"complete\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# use .process_status\n",
    "status_output = pipeline.process_status(request_id=process_output[\"request_id\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(status_output, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "import time\n",
    "time.sleep(10)\n",
    "reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
