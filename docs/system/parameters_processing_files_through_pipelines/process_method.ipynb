{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Parameterizable `.process` Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.process` method, available on every Krixik pipeline, is invoked whenever you wish to process files through a pipeline.\n",
    "\n",
    "This overview of the `.process` method is divided into the following sections:\n",
    "\n",
    "- [Core .process Method Arguments](#core-process-method-arguments)\n",
    "- [Basic Usage and Output Breakdown](#basic-usage-and-output-breakdown)\n",
    "- [Selecting Models Via the modules Argument](#selecting-models-via-the-modules-argument)\n",
    "- [Optional Metadata Arguments](#optional-metadata-arguments)\n",
    "- [Metadata Argument Defaults](#metadata-argument-defaults)\n",
    "- [Automatic File Type Conversions](#automatic-file-type-conversions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core `.process` Method Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.process` method takes five basic arguments (in addition to the `modules` argument and a series of optional metadata arguments, all discussed further below). These five arguments are:\n",
    "\n",
    "- `local_file_path`: (required, str) The local file path of the file you wish to process through the pipeline.\n",
    "\n",
    "- `local_save_directory`: (optional, str) The local directory you want process output saved to. Defaults to the current working directory.\n",
    "\n",
    "- `expire_time`: (optional, int) The amount of time (in seconds) that process output remains on Krixik servers. Defaults to 1800 seconds, which is 30 minutes.\n",
    "\n",
    "- `wait_for_process`: (optional, bool) Indicates whether or not Krixik should wait for your process to complete before returning control of your IDE or notebook. `True` tells Krixik to wait until the process is complete, so you won't be able to execute anything else in the meantime. `False` tells Krixik that you wish to regain control as soon as file upload to the Krixik system has concluded.  When set to `False`, processing status can be examined via the [`.process_status`](../parameters_processing_files_through_pipelines/process_status_method.md) method. Defaults to `True`.\n",
    "\n",
    "- `verbose`: (optional, bool) Determines if Krixik should immediately display process update printouts at your terminal/notebook. Defaults to `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage and Output Breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a single-module pipeline to demonstrate the `.process` method with. We'll use a [`sentiment module`](../../modules/ai_model_modules/sentiment_module.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single-module pipeline for .process demo\n",
    "\n",
    "pipeline_1 = krixik.create_pipeline(name='process_method_1_sentiment',\n",
    "                                    module_chain=['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've locally created a JSON file that holds three snippets that simulate online product reviews. The snippets read as follows:\n",
    "\n",
    "- This recliner is the best damn seat I've ever come across. When I fall asleep on it, which is often, I sleep like a baby.\n",
    "\n",
    "- This recliner is terrible. It broke on its way out of the box, and no matter what I try, it doesn't recline. Avoid at all costs.\n",
    "\n",
    "- I've sat on a lot of recliners in my life. I've forgotten about most of them. I'll forget about this one as well.\n",
    "\n",
    "Keep in mind that input JSON files _must_ follow a very [specific format](../parameters_processing_files_through_pipelines/JSON_input_format.md). If they don't, they'll be rejected by Krixik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .process short input file\n",
    "\n",
    "process_demo_output_1 = pipeline_1.process(local_file_path =\"../../data/input/XXXXX.json\", # the initial local filepath where the input JSON file is stored\n",
    "                                           local_save_directory=\"../../data/output\",  # the local directory that the output file will be saved to\n",
    "                                           expire_time=60 * 10,  # process data will be deleted from the Krixik system in 10 minutes\n",
    "                                           wait_for_process=True,  # wait for process to complete before returning IDE control to user\n",
    "                                           verbose=False)  # do not display process update printouts upon running code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print the output of the process.  Because the output of this particular module-model pair is in JSON format, we can print it nicely with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"parser-pipeline-1\",\n",
      "  \"request_id\": \"e957e17f-ca3c-40bf-afd1-ebca1f27ba51\",\n",
      "  \"file_id\": \"9d94d011-b445-41fa-ae9e-92322726be96\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 9d94d011-b445-41fa-ae9e-92322726be96.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
      "      \"line_numbers\": [\n",
      "        1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.\",\n",
      "      \"line_numbers\": [\n",
      "        2,\n",
      "        3,\n",
      "        4,\n",
      "        5\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"./9d94d011-b445-41fa-ae9e-92322726be96.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of the above process\n",
    "\n",
    "import json\n",
    "\n",
    "json.dumps(process_demo_output_1, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the output:\n",
    "\n",
    "- `status_code`: The HTTP status code for this process (e.g. \"200\", \"500\")\n",
    "\n",
    "- `pipeline`: The `name` of the pipeline we just ran `.process` on.\n",
    "\n",
    "- `request_id`: The unique ID associated with this execution of `.process`.\n",
    "\n",
    "- `file_id`: The unique server-side ID for the now-processed file (and thus its associated output).\n",
    "\n",
    "- `message`: This message specifies SUCCESS or FAILURE for the method call and offers detail.\n",
    "\n",
    "- `warnings`: A message list that includes any warnings related to the method call.\n",
    "\n",
    "- `process_output`: The output of the process. In this case, since the output is in JSON format, it's easily printable in a code notebook.\n",
    "\n",
    "- `process_output_files`: A list of file names and file paths generated as process outputs and saved locally.\n",
    "\n",
    "\n",
    "We can see from `process_output` that our [`sentiment analysis`](../../modules/ai_model_modules/sentiment_module.md) pipeline has worked correctly. Each of the product reviews has been assigned a sentiment value breakdown between positive, negative, and neutral.\n",
    "\n",
    "In addition to being printed here, this process output is also stored in the file indicated in `process_output_files`. Let's load it in and confirm that it shows the same process output we received above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"snippet\": \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
      "    \"line_numbers\": [\n",
      "      1\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"snippet\": \"Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.\",\n",
      "    \"line_numbers\": [\n",
      "      2,\n",
      "      3,\n",
      "      4,\n",
      "      5\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# load in process output from file\n",
    "\n",
    "import json\n",
    "\n",
    "with open(process_output[\"process_output_files\"][0], \"r\") as file:\n",
    "    json.dumps(json.load(file), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Models Via the `modules` Argument\n",
    "\n",
    "The `modules` argument to the `.process` method is optional, but through it you can access a wealth of parameterization options. This argument allows you to parameterize how each module operates, **INCLUDING** the determination of (when applicable) what AI model is active within it.\n",
    "\n",
    "The `modules` argument takes the form of a dictionary with dictionaries within it. On a single-module pipeline it looks like this:\n",
    "\n",
    "```python\n",
    "modules={'<model name>': {'model':'<model selection>', 'params': <dictionary of parameters>}}\n",
    "```\n",
    "\n",
    "Bear in mind that model names are case sensitive.\n",
    "\n",
    "An example for a single-module pipeline that holds a [`caption module`](../../modules/ai_model_modules/caption_module.md) would specifically look like this, `blip-image-captioning-base` being the available model selected:\n",
    "\n",
    "```python\n",
    "modules={'caption': {'model':'blip-image-captioning-base', 'params': {}}}\n",
    "```\n",
    "\n",
    "In the above example `params` is an empty dictionary because [`caption`](../../modules/ai_model_modules/caption_module.md) module models don't take any parameters. Other types of models do, such as the [`text-embedder`](../../modules/ai_model_modules/text-embedder_module.md) module models. This is what the `modules` argument might look like for a single-module [`text-embedder`](../../modules/ai_model_modules/text-embedder_module.md) pipeline:\n",
    "\n",
    "modules={'text-embedder': {'model':'multi-qa-MiniLM-L6-cos-v1', 'params': {'quantize': False}}}\n",
    "\n",
    "`quantize` is a parameter that you can set for [`text-embedder`](../../modules/ai_model_modules/text-embedder_module.md) module models, and only for [`text-embedder`](../../modules/ai_model_modules/text-embedder_module.md) module models.\n",
    "\n",
    "The `modules` argument syntax for multi-module pipelines is similar to the above, but in that case there's one sub-dictionary for every module. For instance, the `modules` argument for a [vector search pipeline](../../examples/search_pipeline_examples/multi_basic_semantic_search.md) that sequentially chains together [`parser`](../../modules/ai_model_modules/parser_module.md), [`text-embedder`](../../modules/ai_model_modules/text-embedder_module.md), and [`vector-db`](../../modules/database_modules/vector-db_module.md) modules might look like this:\n",
    "\n",
    "```python\n",
    "modules={'parser': {'model':'fixed', 'params': {\"chunk_size\": 10, \"overlap_size\": 5}},\n",
    "         'text-embedder': {'model':'all-MiniLM-L6-v2', 'params': {}},\n",
    "         'vector-db': {'model':'faiss', 'params': {}}}\n",
    "```\n",
    "\n",
    "Note that any modules not explicitly called out will take their default values. If you need to specify one module's model or its params, that doesn't mean you need to specify all of them in the pipeline. Consequently, given that in the code immediately above the [`text-embedder`](../../modules/ai_model_modules/text-embedder_module.md) and [`vector-db`](../../modules/database_modules/vector-db_module.md) modules above are being set to their default values, you could achieve the exact same thing by removing them from the code and only leaving the [`parser`](../../modules/ai_model_modules/parser_module.md) module, as follows:\n",
    "\n",
    "```python\n",
    "modules={'parser': {'model':'fixed', 'params': {\"chunk_size\": 10, \"overlap_size\": 5}}}\n",
    "```\n",
    "\n",
    "Find detail on each of our current modules, including available models for each, [here](../../modules/modules_overview.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Metadata Arguments\n",
    "\n",
    "The `.process` method also takes a variety of optional metadata arguments. These do not change how `.process` runs or treats data. Instead, they make your processed files easier to retrieve and organize. You can think of it as a file system for files you've processed through your pipelines.\n",
    "\n",
    "Optional metadata arguments include:\n",
    "\n",
    "- `symbolic_directory_path` (str) - A UNIX-formatted directory path under your account in the Krixik system. Default is `/etc`.\n",
    "\n",
    "- `file_name` (str) - A custom file name that must end with the file extension of the original input file. Default is a randomly-generated string (see below).\n",
    "\n",
    "- `symbolic_file_path` (str) - A combination of `symbolic_directory_path` and `file_name` in a single argument. Default is a concatenation of the default of each.\n",
    "\n",
    "- `file_tags` (list) - A list of custom file tags (each a key-value pair). Default is an empty list.\n",
    "\n",
    "- `file_description` (str) - A custom file description. Default is an empty string.\n",
    "\n",
    "The first four of these—`symbolic_directory_path`, `file_name`, `symbolic_directory_path`, and `file_tags`—can be used as arguments to the [`.list`](../file_system/list_method.md) method and to the [`.keyword_search`](../search_methods/keyword_search_method.md) and [`.semantic_search`](../search_methods/semantic_search_method.md) methods.\n",
    "\n",
    "Note that a file you process through one pipeline is only accessible to that pipeline. If you upload a file to a certain `symbolic_directory_path` on a certain pipeline, for instance, you will not be able to [`.list`](../file_system/list_method.md), [search](../examples/search_pipeline_examples/search_pipelines_overview.md), or otherwise access it from any other pipeline, even if you target the same `symbolic_directory_path` from there.\n",
    "\n",
    "Also note that a `symbolic_file_path` cannot be duplicated within a pipeline. In other words, if on a certain pipeline you `.process` a file to a specified `symbolic_directory_path` and `file_name`, Krixik will not allow you to `.process` any other files with that same combination of `symbolic_file_path` and `file_name`.\n",
    "\n",
    "Let's call the `.process` method once more. We'll use the same product review file as before, but expand our line of code with some of these optional metadata arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .process short input file with optional metadata arguments\n",
    "\n",
    "process_demo_output_2 = pipeline_1.process(local_file_path =\"../../data/input/XXXXX.json\",\n",
    "                                           local_save_directory=\"../../data/output\",\n",
    "                                           expire_time=60 * 10,\n",
    "                                           wait_for_process=True,\n",
    "                                           verbose=False,\n",
    "                                           symbolic_directory_path=\"/my/custom/filepath\",\n",
    "                                           file_name=\"product_reviews.json\",\n",
    "                                           #symbolic_file_path=\"/my/custom/filepath/product_reviews.json\" [an example of how I could combine symbolic_directory_path and file_name]\n",
    "                                           file_tags=[{\"category\": \"furniture\"}, {\"product code\": \"recliner-47b-u11\"}],\n",
    "                                           file_description=\"Three product reviews for the Orwell Cloq recliner.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Argument Defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If no `file_name` is provided, a random one is generated. It takes the form `krixik_generated_file_name_{10 random chars}.ext`, where here `.ext` is the extension of your input file provided in `local_file_path`.\n",
    "\n",
    "- If no `symbolic_directory_path` is provided, the default value it takes is `/etc`.\n",
    "\n",
    "- Note that you cannot define any children directories under the `symbolic_directory_path` `/etc`; it is the catch-all directory, and is not meant to be built under."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic File Type Conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For certain modules, the `.process` method automatically converts the format of some `local_file_path` input files. Conversions currently done by Krixik are:\n",
    "\n",
    "- `pdf` -> `txt`\n",
    "- `docx` -> `txt`\n",
    "- `pptx` -> `txt`\n",
    "- `mp4` -> `mp3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline_1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
