{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `.list` Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the [`.process`](../parameters_processing_files_through_pipelines/process_method.md) method to process one or several files through your chosen pipeline, you can retrieve the record of any file(s) with the `.list` method. You can `.list` by `file_id` or by any other metadata you included when initially processing the file.  \n",
    "\n",
    "This overview of the `.list` method is divided into the following sections:\n",
    "\n",
    "- [.list Method Arguments](#.list-method-arguments)\n",
    "- [Example Pipeline Setup and File Processing](#example-pipeline-setup-and-file-processing)\n",
    "- [Listing by `file_ids`](#listing-by-file_ids)\n",
    "- [Listing by `file_names`](#listing-by-file_names)\n",
    "- [Listing by `symbolic_directory_paths`](#listing-by-symbolic_directory_paths)\n",
    "- [Listing by `file_tags`](#listing-by-file_tags)\n",
    "- [Listing by `created_at` and `updated_at` Bookend Times](#listing-by-created_at-and-updated_at-bookend-times)\n",
    "- [Wildcard Operator Arguments](#wildcard-operator-arguments)\n",
    "- [The Global Root](#the-global-root)\n",
    "- [Using Multiple Arguments with the `.list` Method](#using-multiple-arguments-with-the-.list-method)\n",
    "- [Output Size Cap](#output-size-cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "# import utilities\n",
    "import sys \n",
    "import json\n",
    "import importlib\n",
    "sys.path.append('../../../')\n",
    "reset = importlib.import_module(\"utilities.reset\")\n",
    "reset_pipeline = reset.reset_pipeline\n",
    "\n",
    "# load secrets from a .env file using python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../../../.env\")\n",
    "MY_API_KEY = os.getenv('MY_API_KEY')\n",
    "MY_API_URL = os.getenv('MY_API_URL')\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = MY_API_KEY, \n",
    "            api_url = MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.list` Method Arguments\n",
    "\n",
    "The `.list` method is very versatile. It allows you to list by several different metadata items and by a combination of different metadata items.\n",
    "\n",
    "All of the following arguments are optional. However, you must use at least one argument for the `.list` method to function.\n",
    "\n",
    "For a refresher on file system metadata arguments please visit the [`.process` method overview](../parameters_processing_files_through_pipelines/process_method.md). The metadata arguments you can use for `.list` are:\n",
    "\n",
    "- `file_ids`: A list of one or several `file_id`s to return records for.\n",
    "\n",
    "- `file_names`: A list of  one or several `file_name`s to return records for.\n",
    "\n",
    "- `symbolic_directory_paths`: A list of one or several `symbolic_directory_path`s to return records for.\n",
    "\n",
    "- `symbolic_file_paths`: A list of one or several `symbolic_file_path`s to return records for.\n",
    "\n",
    "- `file_tags`: A list of one or several `file_tag`s to return records for. Note that individual file_tags suffice; if a file has several file tags and you include at least one of them as a `.list` argument, that file's record will be returned.\n",
    "\n",
    "You may use wildcard operators with `file_names`, `symbolic_directory_paths`,`symbolic_file_paths`, and `file_tags` to retrieve records whose exact metadata you don't rememberâ€”or if you wish to retrieve records for a group of files that share similar metadata. More on wildcards operators [later](#wildcard-operator-arguments) in this document.\n",
    "\n",
    "You may also list by timestamp bookends. The `.list` method accepts timestamps based on both the creation and latest-update times of your records. These are strings in the `\"YYYY-MM-DD HH:MM:SS\"` format, or alternatively just in the `\"YYYY-MM-DD\"` format.\n",
    "\n",
    "- `created_at_start`: Filters out all files whose `created_at` time is earlier than what you've specified.\n",
    "\n",
    "- `created_at_end`: Filters out all files whose `created_at` time is after what you've specified.\n",
    "\n",
    "- `last_updated_start`: Filters out all files whose `last_updated` time is earlier than what you've specified.\n",
    "\n",
    "- `last_updated_end`: Filters out all files whose `last_updated` time is after what you've specified.\n",
    "\n",
    "Examples on how to use metadata and timestamps in the `.list` method are included below.\n",
    "\n",
    "Note that file system metadata arguments operate on **OR** logic: for instance, if you `.list` by `file_names`, `file_ids`, and `file_tags`, any file that is a match for any of these will be returned. However, timestamp arguments operate on **AND** logic; all files returned must respect the given timestamp bookends. If two timestamp bookends are given and there is no overlap between them, the `.list` method will return nothing.\n",
    "\n",
    "Finally, the `.list` method takes two additional optional arguments to help you organize your output:\n",
    "\n",
    "- `max_files` (int): Determines the maximum number of file records `.list` should return. Defaults to none.\n",
    "\n",
    "- `sort_order` (str): Specifies how results should be sorted. The two valid values for this argument are 'ascending' and 'descending' (in reference to creation timestamp). Defaults to 'descending'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Pipeline Setup and File Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to create a pipeline and [`.process`](../parameters_processing_files_through_pipelines/process_method.md) a couple of files through it to illustrate usage of `.list`. We'll create a single-module pipeline with a [`parser`](../../modules/support_function_modules/parser_module.md) module and [`.process`](../parameters_processing_files_through_pipelines/process_method.md) some TXT files that hold the text of some English-language classics.  We define optional metadata like file_name, file_tags, and symbolic_directory_path for each process to illustrate how each can be used with `.list` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single-module parser pipeline\n",
    "pipeline = krixik.create_pipeline(name='list_method_1_parser',\n",
    "                                  module_chain=['parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "processes associated with request_id '8594789e-42d3-b069-d0f2-2d5f0d33c3be' failed at module 'summarize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\utilities\\validators\\data\\utilities\\decorators.py:47\u001b[0m, in \u001b[0;36mdatatype_validator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid file extension: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\utilities\\validators\\system\\base\\lower_case.py:163\u001b[0m, in \u001b[0;36mlower_case_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(e)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\system_builder\\base.py:548\u001b[0m, in \u001b[0;36mKrixikBasePipeline.process\u001b[1;34m(self, file_name, symbolic_directory_path, symbolic_file_path, local_file_path, file_tags, file_description, modules, expire_time, verbose, wait_for_process, local_save_directory, download_output, og_local_file_path)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;66;03m# process s3 file via presigned url\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__upload_file_to_s3_via_presignedurl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;66;03m# reset class variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\system_builder\\base.py:391\u001b[0m, in \u001b[0;36mKrixikBasePipeline.__upload_file_to_s3_via_presignedurl\u001b[1;34m(self, verbose)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 391\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\system_builder\\base.py:367\u001b[0m, in \u001b[0;36mKrixikBasePipeline.__upload_file_to_s3_via_presignedurl\u001b[1;34m(self, verbose)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailure_module\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(failure_status\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocesses associated with request_id \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailure_status[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocess_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m failed at module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailure_status[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailure_module\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    369\u001b[0m     )\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: processes associated with request_id '8594789e-42d3-b069-d0f2-2d5f0d33c3be' failed at module 'summarize'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\utilities\\validators\\utilities\\decorators.py:16\u001b[0m, in \u001b[0;36mtype_check_inputs.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msystem_base_type_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_data_type_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatatype_validator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlower_case_decorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\utilities\\validators\\system\\base\\utilities\\decorators.py:143\u001b[0m, in \u001b[0;36mtype_check_inputs.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(e)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\utilities\\validators\\system\\data\\utilities\\decorators.py:137\u001b[0m, in \u001b[0;36mtype_check_inputs.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(e)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_arg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\utilities\\validators\\data\\utilities\\decorators.py:49\u001b[0m, in \u001b[0;36mdatatype_validator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mValueError\u001b[0m: processes associated with request_id '8594789e-42d3-b069-d0f2-2d5f0d33c3be' failed at module 'summarize'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\utilities\\converters\\utilities\\decorators.py:83\u001b[0m, in \u001b[0;36mdatatype_converter_wrapper.<locals>.converter_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\modules\\utilities\\decorators.py:54\u001b[0m, in \u001b[0;36mtype_check_inputs.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_arg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\utilities\\validators\\utilities\\decorators.py:23\u001b[0m, in \u001b[0;36mtype_check_inputs.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mValueError\u001b[0m: processes associated with request_id '8594789e-42d3-b069-d0f2-2d5f0d33c3be' failed at module 'summarize'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# process four files through the pipeline we just created.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m process_output_1 \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../../data/input/Frankenstein partial.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# the initial local filepath where the input file is stored\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mexpire_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# process data will be deleted from the Krixik system in 30 minutes\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mwait_for_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# do not wait for process to complete before returning IDE control to user\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# do not display process update printouts upon running code\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43msymbolic_directory_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/novels/gothic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFrankenstein.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mfile_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauthor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mShelley\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcategory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgothic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcentury\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m19\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m process_output_2 \u001b[38;5;241m=\u001b[39m pipeline_1\u001b[38;5;241m.\u001b[39mprocess(local_file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../data/input/Pride and Prejudice partial.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# the initial local filepath where the input file is stored\u001b[39;00m\n\u001b[0;32m     12\u001b[0m                                       expire_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m,  \u001b[38;5;66;03m# process data will be deleted from the Krixik system in 30 minutes\u001b[39;00m\n\u001b[0;32m     13\u001b[0m                                       wait_for_process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# do not wait for process to complete before returning IDE control to user\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m                                       file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPride and Prejudice.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m                                       file_tags\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAusten\u001b[39m\u001b[38;5;124m\"\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mromance\u001b[39m\u001b[38;5;124m\"\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcentury\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m19\u001b[39m\u001b[38;5;124m\"\u001b[39m}])\n\u001b[0;32m     19\u001b[0m process_output_3 \u001b[38;5;241m=\u001b[39m pipeline_1\u001b[38;5;241m.\u001b[39mprocess(local_file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../data/input/Moby Dick partial.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# the initial local filepath where the input file is stored\u001b[39;00m\n\u001b[0;32m     20\u001b[0m                                       expire_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m,  \u001b[38;5;66;03m# process data will be deleted from the Krixik system in 30 minutes\u001b[39;00m\n\u001b[0;32m     21\u001b[0m                                       wait_for_process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# do not wait for process to complete before returning IDE control to user\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m                                       file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoby Dick.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m                                       file_tags\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMelville\u001b[39m\u001b[38;5;124m\"\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madventure\u001b[39m\u001b[38;5;124m\"\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcentury\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m19\u001b[39m\u001b[38;5;124m\"\u001b[39m}])\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\system_builder\\utilities\\decorators.py:97\u001b[0m, in \u001b[0;36mkwargs_checker.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unexpected_args:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected keyword argument(s) for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(unexpected_args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\system_builder\\functions\\checkin.py:67\u001b[0m, in \u001b[0;36mcheck_init_decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     66\u001b[0m     check_init(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\Desktop\\krixikdocsnoodle\\myenv\\Lib\\site-packages\\krixik\\utilities\\converters\\utilities\\decorators.py:85\u001b[0m, in \u001b[0;36mdatatype_converter_wrapper.<locals>.converter_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(e)\n",
      "\u001b[1;31mValueError\u001b[0m: processes associated with request_id '8594789e-42d3-b069-d0f2-2d5f0d33c3be' failed at module 'summarize'"
     ]
    }
   ],
   "source": [
    "# process files through the pipeline we just created.\n",
    "# we define optional metadata like file_name, file_tags, and symbolic_directory_path for each\n",
    "# to illustrate the ability to list by each.\n",
    "entries = [\n",
    "    {\n",
    "        \"local_file_path\" : \"../../../data/input/frankenstein_very_short.txt\",\n",
    "        \"file_name\": \"Frankenstein.txt\",\n",
    "        \"file_tags\": [{\"author\": \"Shelley\"}, {\"category\": \"gothic\"}, {\"century\": \"19\"}],\n",
    "        \"symbolic_directory_path\": \"/novels/gothic\",\n",
    "    },\n",
    "    {\n",
    "        \"local_file_path\": \"../../../data/input/pride_and_prejudice_very_short.txt\",\n",
    "        \"file_name\": \"Pride and Prejudice.txt\",\n",
    "        \"symbolic_directory_path\": \"/novels/romance\",\n",
    "        \"file_tags\": [{\"author\": \"Austen\"}, {\"category\": \"romance\"}, {\"century\": \"19\"}],\n",
    "    },\n",
    "    {\n",
    "        \"local_file_path\":  \"../../../data/input/moby_dick_very_short.txt\",\n",
    "        \"file_name\": \"Moby Dick.txt\",\n",
    "        \"symbolic_directory_path\": \"/novels/adventure\",\n",
    "        \"file_tags\": [{\"author\": \"Melville\"}, {\"category\": \"adventure\"}, {\"century\": \"19\"}]\n",
    "    }\n",
    "]\n",
    "        \n",
    "# process each file\n",
    "all_process_output = []\n",
    "for entry in entries:\n",
    "    process_output = pipeline.process(local_file_path=entry[\"local_file_path\"], # the initial local filepath where the input file is stored\n",
    "                                       local_save_directory=\"../../../data/output\",  # the local directory that the output file will be saved to\n",
    "                                      expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "                                      wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "                                      verbose=False,  # do not display process update printouts upon running code\n",
    "                                      file_name=entry[\"file_name\"],\n",
    "                                      symbolic_directory_path=entry[\"symbolic_directory_path\"],\n",
    "                                      file_tags=entry[\"file_tags\"])\n",
    "    all_process_output.append(process_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly look at what the output for the last of these processed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"examples-transcribe-multilingual-sentiment-docs\",\n",
      "  \"request_id\": \"1119f07f-e4a1-4021-9668-2f19ea367568\",\n",
      "  \"file_id\": \"efdc2954-9bef-4427-8de1-2bd18a830015\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id efdc2954-9bef-4427-8de1-2bd18a830015.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"For the starting position, we want to see the feed between the hip and shoulders width, the heels on the floor, a neutral column mediated by abdominal tension, the shoulders are lightly in front of the bar or above, straight arms, symmetrical hands and enough width to not rather the knees and we can have a lightly look forward.\",\n",
      "      \"positive\": 0.99,\n",
      "      \"negative\": 0.01,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"To perform the movement, our athlete will push from the heels, he will start to raise the hips and shoulders together, when the bar passes the knees, we extend the hip.\",\n",
      "      \"positive\": 0.996,\n",
      "      \"negative\": 0.004,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"For return, we are going to delay the push of the knees and we are going to push the hip back and the chess forward.\",\n",
      "      \"positive\": 0.006,\n",
      "      \"negative\": 0.994,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"When the bar passes the knees, we have the correct angle of our trunk and we already blessed the knees to approximately half the hip for starting position and resting.\",\n",
      "      \"positive\": 0.493,\n",
      "      \"negative\": 0.507,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Throughout the movement, we want to see the bar close to the body when going up and down.\",\n",
      "      \"positive\": 0.972,\n",
      "      \"negative\": 0.028,\n",
      "      \"neutral\": 0.0\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"/Users/jeremywatt/Desktop/krixik/code/krixik-docs/docs/examples/transcribe/efdc2954-9bef-4427-8de1-2bd18a830015.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of the last process\n",
    "print(json.dumps(all_process_output[-1], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing by `file_ids`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try listing by `file_ids`.\n",
    "\n",
    "You have the `file_id` of each of the four files you processed; each was returned after processing finalized.  \n",
    "\n",
    "You can list by multiple `file_id`s if you so choose by providing a list of desired `file_ids`.\n",
    "\n",
    "For example, to see metadata associated with each file processed above simply pluck out the `file_id` from each processed return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"11dcf756-702c-421c-a85a-49dabc2cca7f\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# .list records for two of the uploaded files via file_ids\n",
    "list_output = pipeline.list(file_ids=[v[\"file_id\"] for v in all_process_output])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a full record for each file was returned. To learn more about each metadata item, visit the documentation for the [`.process`](../parameters_processing_files_through_pipelines/process_method.md) method, where they are gone into detail on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing by `file_names`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also list via `file_name`s. It works just like listing with `file_id`s above, but with `file_name` instead of `file_id`.  We'll list <u>Pride and Prejudice</u> via `file_names`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .list records for one of the uploaded files via file_names\n",
    "list_output = pipeline.list(file_names=[\"Pride and Prejudice.txt\"])\n",
    "\n",
    "# nicely print the output of this .list\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a full record for each file was returned. To learn more about each metadata item, visit the documentation for the [`.process`](../parameters_processing_files_through_pipelines/process_method.md) method, where they are gone into detail on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing by `symbolic_directory_paths`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also list via `symbolic_directory_paths`. It works just like listing with `file_id`s and `file_name`s above, but with `symbolic_directory_path` instead. We'll list <u>Little Women</u> and <u>Moby Dick</u> via `symbolic_directory_paths`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"70c71a76-7ce9-43c7-86e7-838b7fa93d8e\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# .list records for two of the uploaded files via symbolic_directory_paths\n",
    "list_output = pipeline.list(symbolic_directory_paths=[\"/novels/gothic\", \"/novels/adventure\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a full record for each file was returned. To learn more about each metadata item, visit the documentation for the [`.process`](../parameters_processing_files_through_pipelines/process_method.md) method, where they are gone into detail on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing by `file_tags`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list through `file_tags`.  We'll list for 19th century novels and any novels by 'Melville', as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"7915929d-47cc-4fb9-82f6-b737ad823458\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# .list records for two of the uploaded files via symbolic_directory_paths\n",
    "list_output = pipeline.list(file_tags=[{\"author\": \"Melville\"}, {\"century\": 19}])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that every file included the file tag `{\"century\": 19}` when initially processed, all four files were listed. <u>Little Women</u> also included the file tag `{\"author\": \"Melville\"}`, but there's no duplication of results, so that file's record is only listed once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing by `created_at` and `updated_at` Bookend Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate how to `.list` by timestamp bookends, let's first [`.process`](../parameters_processing_files_through_pipelines/process_method.md) one additional file through our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"parser-pipeline-1\",\n",
      "  \"request_id\": \"d3bca30e-d260-4c62-8aa9-91307b21d8b1\",\n",
      "  \"file_id\": \"3b941b6f-bd05-4fbb-83fd-6fea80c25629\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 3b941b6f-bd05-4fbb-83fd-6fea80c25629.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
      "      \"line_numbers\": [\n",
      "        1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.\",\n",
      "      \"line_numbers\": [\n",
      "        2,\n",
      "        3,\n",
      "        4,\n",
      "        5\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"./3b941b6f-bd05-4fbb-83fd-6fea80c25629.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# process an additional file into earlier pipeline\n",
    "process_output = pipeline.process(local_file_path=\"../../../data/input/1984_very_short.txt\", # the initial local filepath where the input JSON file is stored\n",
    "                                  local_save_directory=\"../../../data/output\",  # the local directory that the output file will be saved to\n",
    "                                  expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "                                  wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "                                  verbose=False,  # do not display process update printouts upon running code\n",
    "                                  symbolic_directory_path=\"/novels/dystopian\",\n",
    "                                  file_name=\"1984.txt\",\n",
    "                                  file_tags=[{\"author\": \"Orwell\"}, {\"category\": \"dystopian\"}, {\"century\": 20}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing by timestamp bookends is as straightforward as doing it by file system metadata. The following example only uses one type of bookendâ€”`last_updated_start`â€”but all of them work the same way.\n",
    "\n",
    "Based on the output from the file we just processed and the output from the four earlier files, we'll choose a time/date that falls in the middle of all five `last_updated` timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"aacbb5e9-4701-454b-be2d-16d0f812a201\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:21\",\n",
      "      \"process_id\": \"132561f2-336b-c889-ba9e-500df80fdd38\",\n",
      "      \"created_at\": \"2024-04-26 21:05:21\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        \"pipeline_ordered_modules\": [\n",
      "          \"parser\"\n",
      "        ],\n",
      "        \"pipeline_output_process_keys\": [\n",
      "          \"snippet\"\n",
      "        ]\n",
      "      },\n",
      "      \"file_tags\": [],\n",
      "      \"file_description\": \"\",\n",
      "      \"symbolic_directory_path\": \"/etc\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"3b941b6f-bd05-4fbb-83fd-6fea80c25629\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:21\",\n",
      "      \"file_name\": \"krixik_generated_file_name_zqdsvltyrw.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# .list process records by last_updated timestamp bookend\n",
    "list_output = pipeline.list(created_at_start=process_output[\"created_at\"])\n",
    "\n",
    "# nicely print the output of this .list\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that timestamp bookend arguments operate with **AND** logic: to be listed, a file _must_ fall within the specified timestamp window. This also means that if two timestamp arguments are provided and there is no overlap between them, the `.list` method will return nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wildcard Operator Arguments\n",
    "\n",
    "The wildcard operator is the asterisk: *\n",
    "\n",
    "You can use the wildcard operator * to `.list` records whose exact metadata you don't rememberâ€”or if you wish to `.list` records for a group of files that share similar metadata.\n",
    "\n",
    "For `file_names` and `symbolic_directory_paths` a wildcard may be used as either prefix or suffix:\n",
    "\n",
    "- Example * as a prefix: `*report.txt`\n",
    "- Example * as a suffix: `/home/files/studies*`\n",
    "\n",
    "Note that you don't necessarily have to attach full words to the wildcard operator *. The two above examples could thus instead be:\n",
    "\n",
    "- Example * as a prefix: `*ort.txt`\n",
    "- Example * as a suffix: `/home/files/studi*`\n",
    "\n",
    "For `file_tags` a wildcard may be used for as the value in a key-value pair dictionary. This will return all records with the corresponding key.\n",
    "\n",
    "- Example * in file_tags: `{\"invoice_type\": \"*\"}`\n",
    "\n",
    "Let's dig into `.list` method examples for each of these. First a prefix wildcard in `file_names`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"341c4e07-62a6-47f0-904b-7ff2ee3bbaef\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"file_names\": [\n",
      "            \"some*\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using a wildcard prefix in file_names\n",
    "list_output = pipeline.list(file_names=[\"*e.txt\"])\n",
    "\n",
    "# nicely print the output of this .list\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will return records for every file whose `file_name` ends with \"e.txt\".\n",
    "\n",
    "Now a suffix wildcard in `symbolic_directory_paths`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"b6d53064-2748-4c3a-ac7a-e0325cf8c58f\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"symbolic_directory_paths\": [\n",
      "            \"/my/*\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using wildcard suffix in symbolic_directory_paths\n",
    "list_output = pipeline.list(symbolic_directory_paths=[\"/my/*\"])\n",
    "\n",
    "# nicely print the output of this .list\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will return records for every file whose `symbolic_directory_path` begins with \"/my/\".\n",
    "\n",
    "Now a wildcard operator in `file_tags`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"de17823f-5601-4143-b2ae-c546c173cdc7\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"file_tags_keys\": [\n",
      "            \"author\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using the wildcard operator in file_tags\n",
    "list_output = pipeline.list(file_tags=[{\"author\": \"*\"}])\n",
    "\n",
    "# nicely print the output of this .list\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will return records for every file that has a file_tag whose key is \"author\", regardless of the value.\n",
    "\n",
    "You can also use the wildcard operator with the [`.show_tree`](show_tree_method.md) method, the [`.semantic_search`](../search_methods/semantic_search_method.md) method, and the [`.keyword_search`](../search_methods/keyword_search_method.md) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Global Root\n",
    "\n",
    "As you might have surmised, there is one very special use of the wildcard operator on `symbolic_directory_path`s: we call it \"the global root\". It's leveraged by placing a wildcard operator * right after the root slash, and having nothing else, as follows:\n",
    "\n",
    "```python\n",
    "# example line of code with the global root\n",
    "symbolic_directory_paths=['/*']\n",
    "```\n",
    "\n",
    "Listing the global root returns records for every single file in your pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multiple Arguments with the `.list` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As earlier mentioned, you can jointly use multiple input arguments with the `.list` method. Multiple inputs are combined in a logical **OR** (if they are metadata arguments) or **AND** (if they are timestamp bookends) to retrieve records satisfying what's been requested.\n",
    "\n",
    "As an example, let's combine a timestamp bookend, a `symbolic_file_path`, and `file_tags` in one `.list` method invocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"091a2b5e-4d2f-44cd-9fcf-65a0c80546b7\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"symbolic_directory_paths\": [\n",
      "            \"/my/*\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"file_names\": [\n",
      "            \"some*\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using a combination of input args\n",
    "list_output = pipeline.list(created_at_end=process_output[\"created_at\"],\n",
    "                            symbolic_file_path=\"/novels/gothic/Pride and Prejudice.txt\",\n",
    "                            file_tags=[({\"author\":\"Orwell\"})])\n",
    "\n",
    "# nicely print the output of this .list\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although <u>Pride and Prejudice</u> and <u>Little Women</u> are respectively covered by the `symbolic_file_paths` and `file_tags` arguments, neither of them falls within the indicated timestamp window. Consequently, they are both excluded from the above result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Size Cap\n",
    "\n",
    "The current size limit on output generated by the `.list` method is 5MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
