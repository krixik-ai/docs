{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `list` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using [`process`](system/process.md) to process a file with your chosen pipeline, you can retrieve the associated record if this file using `list` method using its `file_id` and any other optional metadata you included.  \n",
    "\n",
    "This document reviews the `list` method available to every krixik pipeline.\n",
    "\n",
    "\n",
    "- [basic pipeline setup](#basic-pipeline-setup)\n",
    "- [basic usage, required input, and output breakdown](#basic-usage-required-input-and-output-breakdown)\n",
    "- [listing by `file_ids`](#listing-by-file_ids)\n",
    "- [listing by `file_names`](#listing-by-file_names)\n",
    "- [listing by `symbolic_directory_paths`](#listing-by-symbolic_directory_paths)\n",
    "- [listing by `file_tags`](#listing-by-file_tags)\n",
    "- [listing by `created_at` and `updated_at` bookend times](#listing-by-created_at-and-updated_at-bookend-times)\n",
    "- [wildcard arguments](#wildcard-arguments)\n",
    "- [using multiple arguments with `list`](#using-multiple-arguments-with-list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# import utilities\n",
    "import sys \n",
    "import json\n",
    "import importlib\n",
    "sys.path.append('../../')\n",
    "reset = importlib.import_module(\"utilities.reset\")\n",
    "reset_pipeline = reset.reset_pipeline\n",
    "\n",
    "# load secrets from a .env file using python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../../.env\")\n",
    "MY_API_KEY = os.getenv('MY_API_KEY')\n",
    "MY_API_URL = os.getenv('MY_API_URL')\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = MY_API_KEY, \n",
    "            api_url = MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic pipeline setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this document we will use a pipeline consisting of a single [`parser` module](modules/parser.md).  We use [`create_pipeline`](system/create_save_load.md) to instantiate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline with a single module\n",
    "pipeline = krixik.create_pipeline(name=\"list-docs\",\n",
    "                                  module_chain=[\"parser\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage, required input, and output breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the usage of `fetch_output` we process a short file illustrated in the introduction to the [`parser` method](modules/parser.md#basic-usage-and-output-breakdown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../data/input/1984_very_short.txt\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\"../../data/output\", # save output repo data output subdir\n",
    "                                  expire_time=60 * 10,    # set all process data to expire in 10 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False,            # set verbosity to False\n",
    "                                  symbolic_directory_path = \"/my/custom/filepath\",\n",
    "                                  file_name = \"some_snippets.txt\",\n",
    "                                  file_tags = [{\"author\": \"orwell\"}, {\"category\": \"fiction\"}],\n",
    "                                  file_description = \"the first paragraph of 1984\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us examine the returned output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"file_id\": \"3d435c55-05ae-41b6-aee3-76da8c7b0841\",\\n  \"request_id\": \"5e723bee-4939-21f1-52ef-ca0596dd3f1f\",\\n  \"file_name\": \"krixik_generated_file_name_vplttsahnp.txt\",\\n  \"symbolic_directory_path\": \"/etc\",\\n  \"file_tags\": null,\\n  \"file_description\": null\\n}'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "print(json.dumps(process_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can list multiple records with a single execution of `list`, hence the inputs into `list` are as follows:\n",
    "\n",
    "- `file_ids`: (optional) a list of `file_id`'s to return records for\n",
    "- `file_names`: (optional) a list of `file_id`'s to return records for\n",
    "- `symbolic_directory_paths`: (optional) a list of `symbolic_directory_paths`'s to return records for\n",
    "- `symbolic_file_paths`: (optional) a list of `symbolic_directory_path/file_name`'s to return records for\n",
    "- `file_tags`: (optional) a list of `file_tags`'s to return records for\n",
    "\n",
    "You may use wildcard operators with `file_names`, `symbolic_directory_paths`,`symbolic_file_paths`, and `file_tags` to retrieve records with fuzzy matching.\n",
    "\n",
    "You may also list by bookends on the creation and last updated times of your records.  These include:\n",
    "\n",
    "- `created_at_start`: the earliest `created_at` time for record you wish to retrieve\n",
    "- `created_at_end`: the latest `created_at` time for record you wish to retrieve\n",
    "- `last_updated_start`: the earliest `last_updated` time for record you wish to retrieve\n",
    "- `last_updated_end`: the latest `last_updated` time for record you wish to retrieve\n",
    "\n",
    "Moreover you may *mix* these arguments to retrieve records for very specific tranches of your process data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing by `file_ids`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we list the record of this process using its `file_id`.\n",
    "\n",
    "Notice we place this in a list, since in practice we can call `.list` on a list of `file_id`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"11dcf756-702c-421c-a85a-49dabc2cca7f\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records\n",
    "list_output = pipeline.list(file_ids=[process_output[\"file_id\"]])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing by `file_names`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list this file via its `file_name`.  Again we place it in a list, since in practice we may provide a list of `file_name`'s to `.list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"764587e3-7212-429b-baeb-0ba824797fa6\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records\n",
    "list_output = pipeline.list(file_names=[\"some_snippets.txt\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing by `symbolic_directory_paths`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list this file via its `symbolic_directory_path`.  Again we place it in a list, since in practice we may provide a list of `symbolic_directory_path`'s to `.list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"70c71a76-7ce9-43c7-86e7-838b7fa93d8e\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records\n",
    "list_output = pipeline.list(symbolic_directory_paths=[\"/my/custom/filepath\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing by `file_tags`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list this file via its `file_tags`.  Again we place it in a list, since in practice we may provide a list of `file_tags`'s to `.list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"7915929d-47cc-4fb9-82f6-b737ad823458\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records\n",
    "list_output = pipeline.list(file_tags=[{\"author\": \"orwell\"}])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing by `created_at` and `updated_at` bookend times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate how to list by timestamp bookends we first process a file and record the current time (in UTC timezone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"parser-pipeline-1\",\n",
      "  \"request_id\": \"d3bca30e-d260-4c62-8aa9-91307b21d8b1\",\n",
      "  \"file_id\": \"3b941b6f-bd05-4fbb-83fd-6fea80c25629\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 3b941b6f-bd05-4fbb-83fd-6fea80c25629.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
      "      \"line_numbers\": [\n",
      "        1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.\",\n",
      "      \"line_numbers\": [\n",
      "        2,\n",
      "        3,\n",
      "        4,\n",
      "        5\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"./3b941b6f-bd05-4fbb-83fd-6fea80c25629.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../data/input/1984_very_short.txt\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\"../../data/output\", # save output repo data output subdir\n",
    "                                  expire_time=60 * 10,    # set all process data to expire in 10 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False)            # set verbosity to False\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(process_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now list by the `created_at` and `last_updated` timestamps - using bookends `_start` and/or `_end`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"aacbb5e9-4701-454b-be2d-16d0f812a201\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:21\",\n",
      "      \"process_id\": \"132561f2-336b-c889-ba9e-500df80fdd38\",\n",
      "      \"created_at\": \"2024-04-26 21:05:21\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        \"pipeline_ordered_modules\": [\n",
      "          \"parser\"\n",
      "        ],\n",
      "        \"pipeline_output_process_keys\": [\n",
      "          \"snippet\"\n",
      "        ]\n",
      "      },\n",
      "      \"file_tags\": [],\n",
      "      \"file_description\": \"\",\n",
      "      \"symbolic_directory_path\": \"/etc\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"3b941b6f-bd05-4fbb-83fd-6fea80c25629\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:21\",\n",
      "      \"file_name\": \"krixik_generated_file_name_zqdsvltyrw.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records\n",
    "list_output = pipeline.list(created_at_start=list_output[\"items\"][0][\"created_at\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wildcard arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use wildcard * to use fuzzy matching with your record selection as well.\n",
    "\n",
    "For `file_names` and `symbolic_directory_paths` a wildcard may be used as both prefix and suffix.\n",
    "\n",
    "For `file_tags` a wildcard may be used for the value of a tag dictioary to search across all records with a corresopnding key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"341c4e07-62a6-47f0-904b-7ff2ee3bbaef\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"file_names\": [\n",
      "            \"some*\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using wildcard(s)\n",
    "list_output = pipeline.list(file_names=[\"some*\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"b6d53064-2748-4c3a-ac7a-e0325cf8c58f\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"symbolic_directory_paths\": [\n",
      "            \"/my/*\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using wildcard(s)\n",
    "list_output = pipeline.list(symbolic_directory_paths=[\"/my/*\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"de17823f-5601-4143-b2ae-c546c173cdc7\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"file_tags_keys\": [\n",
      "            \"author\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using wildcard(s)\n",
    "list_output = pipeline.list(file_tags=[{\"author\": \"*\"}])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using multiple arguments with `list`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use multiple input arguments jointly with `list`.  Multiple inputs are combined in a logical AND to retrieve records satisfying all input requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"091a2b5e-4d2f-44cd-9fcf-65a0c80546b7\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"symbolic_directory_paths\": [\n",
      "            \"/my/*\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"file_names\": [\n",
      "            \"some*\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using a mix of input args\n",
    "list_output = pipeline.list(file_names = [\"some*\"],\n",
    "                            symbolic_directory_paths=[\"/my/*\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "print(json.dumps(list_output, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
