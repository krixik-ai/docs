{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `semantic_search` Method\n",
    "\n",
    "Krixik's `semantic_search` method enables semantic search on documents processed through certain pipelines. Much has been written about semantic search, but in a nutshell, instead of searching a document for specific keywords, it searches for text similar in _meaning_ to the string that's been queried for. Contrast this to [keyword search](keyword_search_method.md).\n",
    "\n",
    "Given that the `semantic_search` method both [embeds](../../modules/ai_modules/text-embedder_module.md) the query and performs the search, it can only be used with pipelines containing both a [`text-embedder`](../../modules/ai_modules/text-embedder_module.md) module and a [`vector-db`](../../modules/database_modules/vector-db_module.md) module in immediate succession.\n",
    "\n",
    "This overview of the `semantic_search` method is divided into the following sections:\n",
    "\n",
    "- [semantic_search Method Arguments](#semantic_search-method-arguments)\n",
    "- [Example Pipeline Setup and File Processing](#example-pipeline-setup-and-file-processing)\n",
    "- [Example Semantic Searches](#example-semantic-searches)\n",
    "- [Output Size Cap](#output-size-cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "# import utilities\n",
    "import sys\n",
    "import json\n",
    "import importlib\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "reset = importlib.import_module(\"utilities.reset\")\n",
    "reset_pipeline = reset.reset_pipeline\n",
    "\n",
    "# load secrets from a .env file using python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../../../.env\")\n",
    "MY_API_KEY = os.getenv(\"MY_API_KEY\")\n",
    "MY_API_URL = os.getenv(\"MY_API_URL\")\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "\n",
    "krixik.init(api_key=MY_API_KEY, api_url=MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `semantic_search` Method Arguments\n",
    "\n",
    "The `semantic_search` method takes one required argument and at least one of several optional arguments. The required argument is:\n",
    "\n",
    "- `query` (str) - A string whose meaning will be searched for across the target document. The closest matches (i.e. snippets of text that most match the query in meaning) will be returned.\n",
    "\n",
    "The optional arguments are the same arguments that the [`list`](../file_system/list_method.md) method takes—both metadata and timestamp bookends—so please take a moment to [review them here](../file_system/list_method.md#list-method-arguments). As with the [`list`](../file_system/list_method.md) method, you can semantically search across several files at the same time because all metadata arguments are submitted to the `semantic_search` method in list format. All optional argument elements are the same as for the [`list`](../file_system/list_method.md) method, including the wildcard operator and the global root.\n",
    "\n",
    "If none of these optional arguments is present, the `semantic_search` method will not work because there will be nothing to search through.\n",
    "\n",
    "Like the [`list`](../file_system/list_method.md) method, the `semantic_search` method also accepts the optional `max_files` and `sort_order` arguments, though their function changes a bit:\n",
    "\n",
    "- `max_files` - Specifies up to how many files should be searched through. Default is none.\n",
    "\n",
    "- `sort_order` - Here takes three possible values: 'ascending', descending', and now 'global'. The first two sort results by the file they're in (the files are sorted by the creation timestamp of the file), and 'global' combines all files and returns the very best results across all files. Default is 'descending'.\n",
    "\n",
    "Finally, the `semantic_search` method accepts one optional method that is unique to it:\n",
    "\n",
    "- `k` (int) - Specifies up to how many results will be returned per queried file. Default is 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Pipeline Setup and File Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this document's examples we will use a pipeline consisting of three modules: a [`parser module`](../../modules/support_function_modules/parser_module.md), a [`text-embedder module`](../../modules/ai_modules/text-embedder_module.md), and a [`vector-db module`](../../modules/database_modules/vector-db_module.md). This is the basic semantic search [pipeline](../../examples/search_pipeline_examples/multi_basic_semantic_search.md). We use the [`create_pipeline`](../pipeline_creation/create_pipeline.md) method to instantiate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the basic semantic search pipeline\n",
    "pipeline = krixik.create_pipeline(\n",
    "    name=\"semantic_search_method_1_parser_text-embedder_vector-db\", module_chain=[\"parser\", \"text-embedder\", \"vector-db\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline ready, we'll [`process`](../parameters_processing_files_through_pipelines/process_method.md) a few text files through it so we have something to search through. Let's use the same files we used in the [`list` method documentation](../file_system/list_method.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add four files to the pipeline we just created.\n",
    "output_1 = pipeline.process(\n",
    "    local_file_path=\"../../../data/input/frankenstein_very_short.txt\",  # the initial local filepath where the input JSON file is stored\n",
    "    local_save_directory=\"../../../data/output\",\n",
    "    expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "    wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "    verbose=False,  # do not display process update printouts upon running code\n",
    "    symbolic_directory_path=\"/novels/gothic\",\n",
    "    file_name=\"Frankenstein.txt\",\n",
    ")\n",
    "\n",
    "output_2 = pipeline.process(\n",
    "    local_file_path=\"../../../data/input/pride_and_prejudice_very_short.txt\",  # the initial local filepath where the input JSON file is stored\n",
    "    local_save_directory=\"../../../data/output\",\n",
    "    expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "    wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "    verbose=False,  # do not display process update printouts upon running code\n",
    "    symbolic_directory_path=\"/novels/romance\",\n",
    "    file_name=\"Pride and Prejudice.txt\",\n",
    ")\n",
    "\n",
    "output_3 = pipeline.process(\n",
    "    local_file_path=\"../../../data/input/moby_dick_very_short.txt\",  # the initial local filepath where the input JSON file is stored\n",
    "    local_save_directory=\"../../../data/output\",\n",
    "    expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "    wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "    verbose=False,  # do not display process update printouts upon running code\n",
    "    symbolic_directory_path=\"/novels/adventure\",\n",
    "    file_name=\"Moby Dick.txt\",\n",
    ")\n",
    "\n",
    "output_4 = pipeline.process(\n",
    "    local_file_path=\"../../../data/input/little_women_very_short.txt\",  # the initial local filepath where the input JSON file is stored\n",
    "    local_save_directory=\"../../../data/output\",\n",
    "    expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "    wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "    verbose=False,  # do not display process update printouts upon running code\n",
    "    symbolic_directory_path=\"/novels/bildungsroman\",\n",
    "    file_name=\"Little Women.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the output for one of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"semantic_search_method_1_parser_text-embedder_vector-db\",\n",
      "  \"request_id\": \"2615ca13-adf7-4951-9ab9-bf3465ea47ce\",\n",
      "  \"file_id\": \"c9ac7eae-81ac-451f-b15e-ead72ee234c9\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id c9ac7eae-81ac-451f-b15e-ead72ee234c9.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"c:\\\\Users\\\\Lucas\\\\Desktop\\\\krixikdocsnoodle\\\\docs\\\\system\\\\search_methods/c9ac7eae-81ac-451f-b15e-ead72ee234c9.faiss\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of one of the above processes\n",
    "print(json.dumps(output_2, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of `process_output` is `null` because the return object is a database, so it cannot be printed here. You can review this database in the local location provided in the `process_output_files`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Semantic Searches\n",
    "\n",
    "With files now processed through the pipeline we can run the `semantic_search` method on it.\n",
    "\n",
    "Let's try an example in which we query one of the files file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"85192b31-b872-4d40-b4bb-2cbcf926fead\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"7c352bfe-3487-4ccd-acc6-144f8b7cdfbf\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"little women.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/bildungsroman\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 2068,\n",
      "        \"created_at\": \"2024-05-20 19:11:26\",\n",
      "        \"last_updated\": \"2024-05-20 19:11:26\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"How is your cold, Meg?\",\n",
      "          \"line_numbers\": [\n",
      "            940\n",
      "          ],\n",
      "          \"distance\": 0.27\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Shivering, dripping, and crying, they got Amy home; and, after an\\nexciting time of it, she fell asleep, rolled in blankets, before a hot\\nfire.\",\n",
      "          \"line_numbers\": [\n",
      "            4016,\n",
      "            4017,\n",
      "            4018,\n",
      "            4019\n",
      "          ],\n",
      "          \"distance\": 0.274\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Jo saw her coming, and turned her back; Laurie did not see, for he\\nwas carefully skating along the shore, sounding the ice, for a warm\\nspell had preceded the cold snap.\",\n",
      "          \"line_numbers\": [\n",
      "            3966,\n",
      "            3967,\n",
      "            3968\n",
      "          ],\n",
      "          \"distance\": 0.274\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Jo was the first to wake in the gray dawn of Christmas morning.\",\n",
      "          \"line_numbers\": [\n",
      "            1134,\n",
      "            1135,\n",
      "            1136\n",
      "          ],\n",
      "          \"distance\": 0.287\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Everybody dawdled\\nthat morning, and it was noon before the girls found energy enough even\\nto take up their worsted work.\",\n",
      "          \"line_numbers\": [\n",
      "            4432,\n",
      "            4433,\n",
      "            4434\n",
      "          ],\n",
      "          \"distance\": 0.288\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# perform semantic_search over one file\n",
    "semantic_output = pipeline.semantic_search(query=\"It was cold night.\", file_names=[\"Little Women.txt\"])\n",
    "\n",
    "# nicely print the output of this search\n",
    "print(json.dumps(semantic_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to returning the snippets that are closest in meaning to our query, we also see the calculated vector distance (in a way, the distance in meaning) between each result and the query. The shorter this distance is, the closer in meaning the result to the query. The `semantic_search` method returns the snippets with the shortest vector distance to query, ranked in ascending order within each file.\n",
    "\n",
    "When `sort_order` is set to 'global', results from all files are combined and the method returns the snippets with the shortest distance to query, ranked in ascending order, regardless of what file each result may be in. Let's give this a shot by searching through multiple files with the [wildcard operator](../file_system/list_method.md#wildcard-operator-arguments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"76b5d209-8bb4-467d-b454-4e784bf32ad4\",\n",
      "  \"message\": \"Successfully queried 4 user files.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"snippet\": \"It was a Saturday night\\nin December.\",\n",
      "      \"distance\": 0.189,\n",
      "      \"line_numbers\": [\n",
      "        1048,\n",
      "        1049\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"23f62ad0-daf6-448d-a44b-47a447b2f6d7\",\n",
      "        \"file_name\": \"moby dick.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/adventure\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:10:46\",\n",
      "        \"last_updated\": \"2024-05-20 19:10:46\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"It was a\\nvery dubious-looking, nay, a very dark and dismal night, bitingly cold\\nand cheerless.\",\n",
      "      \"distance\": 0.203,\n",
      "      \"line_numbers\": [\n",
      "        1072,\n",
      "        1073,\n",
      "        1074\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"23f62ad0-daf6-448d-a44b-47a447b2f6d7\",\n",
      "        \"file_name\": \"moby dick.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/adventure\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:10:46\",\n",
      "        \"last_updated\": \"2024-05-20 19:10:46\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"A great fall of snow had taken\\nplace the night before, and the fields were of one uniform white; the\\nappearance was disconsolate, and I found my feet chilled by the cold\\ndamp substance that covered the ground.\",\n",
      "      \"distance\": 0.242,\n",
      "      \"line_numbers\": [\n",
      "        3236,\n",
      "        3237,\n",
      "        3238,\n",
      "        3239\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"4830bdad-7b1b-46ad-9e70-2a60c077849f\",\n",
      "        \"file_name\": \"frankenstein.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/gothic\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:09:33\",\n",
      "        \"last_updated\": \"2024-05-20 19:09:33\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"By degrees, after the morning\\u2019s dawn,\\nsleep came.\",\n",
      "      \"distance\": 0.247,\n",
      "      \"line_numbers\": [\n",
      "        1233,\n",
      "        1234\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"4830bdad-7b1b-46ad-9e70-2a60c077849f\",\n",
      "        \"file_name\": \"frankenstein.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/gothic\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:09:33\",\n",
      "        \"last_updated\": \"2024-05-20 19:09:33\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"I was still cold when under one of the trees I found a huge cloak, with\\nwhich I covered myself, and sat down upon the ground.\",\n",
      "      \"distance\": 0.25,\n",
      "      \"line_numbers\": [\n",
      "        3165,\n",
      "        3166\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"4830bdad-7b1b-46ad-9e70-2a60c077849f\",\n",
      "        \"file_name\": \"frankenstein.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/gothic\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:09:33\",\n",
      "        \"last_updated\": \"2024-05-20 19:09:33\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"I then paused, and a\\ncold shivering came over me.\",\n",
      "      \"distance\": 0.252,\n",
      "      \"line_numbers\": [\n",
      "        1665,\n",
      "        1666\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"4830bdad-7b1b-46ad-9e70-2a60c077849f\",\n",
      "        \"file_name\": \"frankenstein.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/gothic\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:09:33\",\n",
      "        \"last_updated\": \"2024-05-20 19:09:33\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"The sky had changed from clear, sunny cold, to driving\\nsleet and mist.\",\n",
      "      \"distance\": 0.26,\n",
      "      \"line_numbers\": [\n",
      "        2062,\n",
      "        2063\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"23f62ad0-daf6-448d-a44b-47a447b2f6d7\",\n",
      "        \"file_name\": \"moby dick.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/adventure\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:10:46\",\n",
      "        \"last_updated\": \"2024-05-20 19:10:46\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"We felt\\nvery nice and snug, the more so since it was so chilly out of doors;\\nindeed out of bed-clothes too, seeing that there was no fire in the\\nroom.\",\n",
      "      \"distance\": 0.264,\n",
      "      \"line_numbers\": [\n",
      "        2727,\n",
      "        2728,\n",
      "        2729,\n",
      "        2730\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"23f62ad0-daf6-448d-a44b-47a447b2f6d7\",\n",
      "        \"file_name\": \"moby dick.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/adventure\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:10:46\",\n",
      "        \"last_updated\": \"2024-05-20 19:10:46\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"How is your cold, Meg?\",\n",
      "      \"distance\": 0.27,\n",
      "      \"line_numbers\": [\n",
      "        940\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"7c352bfe-3487-4ccd-acc6-144f8b7cdfbf\",\n",
      "        \"file_name\": \"little women.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/bildungsroman\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:11:26\",\n",
      "        \"last_updated\": \"2024-05-20 19:11:26\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Shivering, dripping, and crying, they got Amy home; and, after an\\nexciting time of it, she fell asleep, rolled in blankets, before a hot\\nfire.\",\n",
      "      \"distance\": 0.274,\n",
      "      \"line_numbers\": [\n",
      "        4016,\n",
      "        4017,\n",
      "        4018,\n",
      "        4019\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"7c352bfe-3487-4ccd-acc6-144f8b7cdfbf\",\n",
      "        \"file_name\": \"little women.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/bildungsroman\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:11:26\",\n",
      "        \"last_updated\": \"2024-05-20 19:11:26\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Jo saw her coming, and turned her back; Laurie did not see, for he\\nwas carefully skating along the shore, sounding the ice, for a warm\\nspell had preceded the cold snap.\",\n",
      "      \"distance\": 0.274,\n",
      "      \"line_numbers\": [\n",
      "        3966,\n",
      "        3967,\n",
      "        3968\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"7c352bfe-3487-4ccd-acc6-144f8b7cdfbf\",\n",
      "        \"file_name\": \"little women.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/bildungsroman\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:11:26\",\n",
      "        \"last_updated\": \"2024-05-20 19:11:26\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Jo was the first to wake in the gray dawn of Christmas morning.\",\n",
      "      \"distance\": 0.287,\n",
      "      \"line_numbers\": [\n",
      "        1134,\n",
      "        1135,\n",
      "        1136\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"7c352bfe-3487-4ccd-acc6-144f8b7cdfbf\",\n",
      "        \"file_name\": \"little women.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/bildungsroman\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:11:26\",\n",
      "        \"last_updated\": \"2024-05-20 19:11:26\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Miss\\nBennet had slept ill, and though up, was very feverish, and not well\\nenough to leave her room.\",\n",
      "      \"distance\": 0.29,\n",
      "      \"line_numbers\": [\n",
      "        1792,\n",
      "        1793,\n",
      "        1794\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"c9ac7eae-81ac-451f-b15e-ead72ee234c9\",\n",
      "        \"file_name\": \"pride and prejudice.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/romance\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:10:16\",\n",
      "        \"last_updated\": \"2024-05-20 19:10:16\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"The apothecary came; and having\\nexamined his patient, said, as might be supposed, that she had caught a\\nviolent cold, and that they must endeavour to get the better of it;\\nadvised her to return to bed, and promised her some draughts.\",\n",
      "      \"distance\": 0.304,\n",
      "      \"line_numbers\": [\n",
      "        1805,\n",
      "        1806,\n",
      "        1807,\n",
      "        1808\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"c9ac7eae-81ac-451f-b15e-ead72ee234c9\",\n",
      "        \"file_name\": \"pride and prejudice.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/romance\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:10:16\",\n",
      "        \"last_updated\": \"2024-05-20 19:10:16\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Why must _she_ be scampering about the\\ncountry, because her sister had a cold?\",\n",
      "      \"distance\": 0.309,\n",
      "      \"line_numbers\": [\n",
      "        1876,\n",
      "        1877\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"c9ac7eae-81ac-451f-b15e-ead72ee234c9\",\n",
      "        \"file_name\": \"pride and prejudice.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/romance\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:10:16\",\n",
      "        \"last_updated\": \"2024-05-20 19:10:16\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"People do not die of little\\ntrifling colds.\",\n",
      "      \"distance\": 0.321,\n",
      "      \"line_numbers\": [\n",
      "        1740,\n",
      "        1741\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"c9ac7eae-81ac-451f-b15e-ead72ee234c9\",\n",
      "        \"file_name\": \"pride and prejudice.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/romance\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-05-20 19:10:16\",\n",
      "        \"last_updated\": \"2024-05-20 19:10:16\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# perform semantic_search over multiple files\n",
    "semantic_output = pipeline.semantic_search(query=\"It was cold night.\", symbolic_directory_paths=[\"/novels*\"], sort_order=\"global\", k=4)\n",
    "\n",
    "# nicely print the output of this search\n",
    "print(json.dumps(semantic_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, results from all the files have been combined, and the result ranked at the top has the shortest query-result distance of the entire file set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Size Cap\n",
    "\n",
    "The current size limit on output generated by the `semantic_search` method is 5MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
